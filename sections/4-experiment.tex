\section{Fallbeispiel AXA Gesundheitsvorsorge}

In diesem Kapitel wird die Anwendbarkeit der künstlichen Intelligenz zur automatisierten Verarbeitung von eingereichten Rechnungen bei der AXA Gesundheitsvorsorge überprüft.

Es wird erst ein Überblick über den Prozess gewährt, aus welchem anschliessend Aufgaben abgeleitet werden, welche mit Hilfe von künstlicher Intelligenz automatisiert werden sollen.

\subsection{Einleitung}

\todo[inline]{Grober Abriss über den Umfang des Prototypen

Umfang reduzieren auf 2 Teilaspekte:

- Rechnungsklassifizierung (hierzu 2 Ansätze (Pixel vs. OCR) vergleichen)

- Informationsextraktion (e.g. von Patienten namen und des Totalbetrags)
}

Der Prozess der Rechnungseinreichung und -verarbeitung (vgl. Abbildung \ref{prozessaxa}) der AXA kann aufgrund zwei verschiedener Ereignisse angestossen werden. In jedem Fall reicht der Kunde eine Rechnung ein. Dies kann er entweder digital, im Kundenportal, oder per Post machen. 

\begin{figure}[h]
    \captionsetup{width=.8\linewidth}
    \caption{Prozess der Rechnungseinreichung und -verarbeitung der AXA Gesundheitsvorsorge. Vom Kunden per Post oder über das Kundenportal eingereichte Rechnungen durchlaufen mehrere Prozessschritte in Verantwortung unterschiedlicher Organisationen.}
    \label{prozessaxa}
    \centering
    \vspace{0.2cm}
    \includegraphics[width=\textwidth]{graphics/rechnungseinreichung-bpmn.png}
\end{figure}

\todo[inline]{Optimierung Grafik

Kundenportal löschen

Labels der Linien besser umbrechen

Linien mit Pfeilen

Auszahlung -> Rückmeldung an Kunde (Auszahlung oder Rückweisung)

Eventuelle Rückfragen und frühzeitige Abweisungen (QG) aufzeigen

OKP weiterleitung

Nur den Schritt "Indexierung" einfärben

--> See new Download}

Im Kundenportal hat der Kunde die Möglichkeit eine Rechnung hochzuladen. Dabei kann er entweder ein Dokument auf seinem Endgerät wählen oder die Kamera seines Geräts nutzen, um eine Rechnung zu fotografieren.

Nach erfolgreichem Hochladen der Rechnung im Kundenportal durchläuft diese eine erste manuelle Qualitätsprüfung. Diese Qualitätsprüfung wurde eingeführt, da hochgeladene Rechnung teilweise ungenügende Qualität vorweisen. Entspricht die Rechnung nicht den Qualitätsanforderungen oder fehlt eine Seite oder eine ärztliche Verordnung, so wird der Kunde gebeten, die vollständige Rechnung erneut hochzuladen.

Nach erfolgreicher Qualitätsprüfung wird die Rechnung an den Scanning und Indexierungsdienstleister der AXA weitergeleitet.

Entscheidet sich der Kunde für die Einreichung per Post, so wird sein Brief direkt an den Scanning und Indexierungsdienstleister der AXA weitergeleitet, bei welchem die Rechnung eingescannt wird.

Nach beiden dieser Einstiegspunkten in den Prozess indexiert nun der Scanning und Indexierungsdienstleister der AXA die eingereichte Rechnung. Dieser Aufgabenschritt erfolgt teilweise automatisiert und teilweise manuell. Wie genau die Indexierung abläuft ist nicht bekannt, da diese Dienstleistung eingekauft wird.

Nach der Indexierung werden die Scans sowie das strukturierte Resultat der Indexierung elektronisch an das Kernsystem der AXA Gesundheitsvorsorge übermittelt. Dieses Kern\-system verarbeitet die eingegangenen Rechnungen aufgrund eines Regelwerks. Kann die Rechnung nicht verarbeitet werden, weil diese nicht korrekt Indexiert wurde oder Informationen fehlen, muss eine FachspezialistIn eingreiffen. Nach allfälligen Rückfragen und Korrekturen durch die FachspezialistIn wird die Rechnung verarbeitet. 

Nach der Erfolgreichen Verarbeitung der Rechnung wird der Kunde elektronisch informiert, ob die beanspruchten Leistungen versichert sind und ob eine Rückvergütung ausbezahlt wird.

Hat der Kunde die AXA bevollmächtigt, so wird die Rechnung in gewissen Fällen, je nach Rechnungspositionen, automatisiert an die Grundversicherung des Kunden weitergeleitet. 

Ziel der AXA Gesundheitsvorsorge ist es, diesen Prozess für eingereichte Rechnungen, welche Fitnesscenter und Optiker betreffen, vollständig zu automatisieren. Dabei gibt es in diversen Bereichen Herausforderungen, welche aktuell angegangen werden. Diese Arbeit hat zum Ziel, die Herausforderungen im Bereich der Indexierung anzugehen. Es wird untersucht, ob die Anwendung künstlicher Intelligenz eine Automatisierung der Indexierung ermöglichen kann.

% Um den Umfang dieser Analyse einzugrenzen, wird der Fokus auf Rechnungen von Optikern, Fitnesscentern und Sportvereinen gelegt. Diese Rechnungen machen 23\% der eingereichten Rechnungen aus und sind Versicherungstechnisch relativ einfach handzuhaben.

% optiker 2660 -> 
% fitness 2055
% sportsclub 847
% =subtotla 5562
% other 18881
% =total 24443


\subsection{Vorgehen und Methodik}

\todo[inline]{Abschnitt überarbeiten...}

Die Anwendbarkeit der künstlichen Intelligenz für dieses Fallbeispiel wird durch zwei praktische Experimente geprüft. Dafür werden zuerst die Anforderungen und Bewertungskriterien an die Indexierung gesammelt und anschliessend Teilaufgaben abgeleitet. 

Für jede Teilaufgabe werden Messkriterien definiert, welche die Grundlagen für die Bewertung der Gesamtaufgabe bilden. Es wird für jede Teilaufgabe mindestens ein Experiment durchgeführt.

Für jedes Experiment wird eine aufgabenspezifische künstliche Intelligenz geschaffen, welche anhand der für die Teilaufgabe definierten Messkriterien bewertet wird.

\subsection{Anforderungen}

Um Rechnungen von Fitnesscenter und Optikern automatisiert verarbeiten zu können, müssen diese Rechnungen erkannt und die notwendigen Informationen, welche nachfolgend genauer spezifiziert werden, extrahiert werden.

Um eine Rechnung eines Optikers zu verarbeiten, sind folgende Informationen relevant:

\begin{itemize}
    \item \textbf{Leistungsbezüger}
    
    Es muss ermittelt werden, für wen die Rechnung ausgestellt wurde. Anhand dieser Information wird geprüft, ob und wie diese Person bei der AXA versichert ist. Auch wird damit geprüft, dass der maximal versicherte Betrag noch nicht ausgeschöpft ist.
    
    Ist der Leistungsbezüger minderjährig, so wird ein gewisser Betrag von der Grundversicherung übernommen. In diesem Fall wird dieser Betrag von der Rückvergütung der AXA abgezogen und die Rechnung an die Grundversicherung weitergeleitet.
    
    \item \textbf{Totalbetrag der Rechnung (inkl. Währung)}
    
    Dieser Betrag bildet die Grundlage zur Berechnung der geschuldeten Leistung an den Kunden. 
    
    Einzelne Rechnungspositionen sind für Rechnungen von Optikern nicht relevant.
    
    \item \textbf{Hinweis auf eine ärztliche Verordnung}
    
    Besteht eine ärztliche Verordnung, ist ein gewisser Betrag bei der Grundversicherung versichert. In diesem Fall wird dieser Betrag von der Rückvergütung der AXA abgezogen und die Rechnung an die Grundversicherung weitergeleitet.
\end{itemize}

%\paragraph{
%    \textbf{Relevante Attribute einer Rechnung für einen Sportverein}
%}

%Eine Rechnung eines Sportvereins wird bei der AXA Anhand folgender Attribute beurteilt:

%\begin{itemize}
%    \item \textbf{Leistungsbezüger}
%    
%    Es muss ermittelt werden, für wen die Rechnung ausgestellt wurde. Anhand dieser Information wird geprüft ob und wie diese Person bei der AXA Versichert ist. Auch wird damit geprüft, dass der maximal versicherte Betrag noch nicht ausgeschöpft ist.
%    \item \textbf{Totalbetrag der Rechnung (inkl. Währung):}
%    
%    Dieser Betrag bildet die Grundlage zur Berechung des geschuldeten Betrages. 
%    
%    Einzelne Rechnungspoisition sind für Rechnungen eines Sportvereins nicht relevant.
%    \item \textbf{Sportart}
%    
%    Die AXA anerkennt alle olympischen Sportarten. Das bedeutet, gewisse Sportarten sind nicht versichert. Es muss also die Sportart ermittelt werden, um die Versicherungsdeckung zu prüfen.
%\end{itemize}

Folgende Informationen sind relevant, um eine Rechnung für ein Fitness-Abo zu verarbeiten:

\begin{itemize}
    \item \textbf{Leistungsbezüger}
    
    Es muss ermittelt werden, für wen die Rechnung ausgestellt wurde. Anhand dieser Information wird geprüft ob und wie diese Person bei der AXA versichert ist. Auch wird damit geprüft, dass der maximal versicherte Betrag noch nicht ausgeschöpft ist.
    \item \textbf{Totalbetrag der Rechnung (inkl. Währung):}
    
    Dieser Betrag bildet die Grundlage zur Berechnung der geschuldeten Leistung an den Kunden. 
    
    Einzelne Rechnungspositionen sind für Rechnungen von Optikern nicht relevant.
    \item \textbf{Fitnesscenter (Leistungserbringer)}
    
    Die AXA anerkennt alle Fitnesscenter mit dem Label Qualitop von Qualicert oder mit einer Bewertung von mindestens 3 Sternen bei Fitnessguide.
\end{itemize}

Anahnd dieser Informationen können Rechnungen automatisiert verarbeitet werden. Es ist wichtig, dass diese Informationen korrekt extrahiert werden. Durch die Automatisierung entfällt jegliche manuelle Prüfung und Fehler würden, wenn überhaupt, erst dem Kunden auffallen. 

\todo[inline]{Hier definieren:

- Wieviel \% der Fitness und Optiker Rechnungen sollen automatisiert verarbeitet werden

- Wie viele Fehler dürfen gemacht werden (Falsche klassifiziert, falsche Beträge, falsche Leistungsbezüger)

- ... andere Metriken}

\subsection{Übersicht}

Wie in den Anforderungen bereits ersichtlich, besteht die Aufgabe aus zwei Teilschritten. Als erstes 

Um die Aufgabenstellung besser zu verstehen und Schrittweise bearbeiten zu können, wird diese in zwei Teilaufgaben unterteilt. 

Im ersten Schritt werden Rechnungen klassifiziert, damit Rechnungen von Optikern und Fitnesscentern zur weiteren Verarbeitung ausgelenkt werden können. 

Im zweiten Schritt werden die notwendigen Informationen aus den Rechnungen extrahiert. Die Klassifizierung aus dem ersten Schritt erlaubt es, in diesem Schritt ein System zu verwenden, welches auf eine Klasse von Rechnungen spezialisiert ist. 

\subsection{Teil 1 - Klassifizierung von Rechnungen}

Die Klassifizierung dient dazu, eine Rechnung einer bestimmten Art (Klasse) zuzuweisen. Die Klassen \enquote{Optiker} und \enquote{Fitness} sind durch die Anforderungen gegeben. Neben diesen Klassen könnten Rechnungen noch in viele weitere Klassen eingeteilt werden. Um dem Rechnung zu tragen, werden in diesem Experiment  Rechnungen den Klassen \enquote{Optiker}, \enquote{Fitness}, \enquote{Sportverein} und \enquote{Übrige} zugewiesen. In der späteren Anwendung wäre es denkbar, die Anzahl Klassen zu erhöhen und somit auch andere Arten von Rechnungen zu Automatisieren.

Als Ausgangspunkt für die Klassifizierung steht ein Bild einer Rechnung. Die Klassifizierung von Bildern respektive Fotos ist eine Kernproblematik der Computer Vision und bildet in diesem Bereich die Grundlage für die Lösung viele weitere Problematiken~\autocite{StanfordGithubClassification}. 

% Die Wichtigkeit der Bildklassifizierung zeigt die Organisation ImageNet. ImageNet aht es zum Ziel, Forschern einen einfachen Zugang zu Datensätzen von Bildern zu gewähren. Seit 2010 wurden bereits sieben Wettbewerbe im Bereich der Computer Vision veranstaltet rund um die Klassifikation von Bildern und die Erkennung von Objekten auf diesen Bildern~\autocite{ImageNet2019}. 

Es liegt nahe, die Klassifizierung der Rechnungen mit Bild-basierten Modellen anzugehen. Im folgenden Kapitel wird dieser Ansatz verfolgt.

Nicht nur im Bereich der Computer Vision ist das Thema der Klassifikation ein viel behandeltes. Im Bereich des Natural Language Processing ist die Klassifikation von Wörtern, Sätzen oder ganzen Texten eine bekannte Problemstellung. Die sogenannte Text Classification ist die Grundlage für viele Applikationen, welche mit Texten arbeiten. So verwenden beispielsweise Mail-Server Text Classification um zu entscheiden, ob ein E-Mail Spam ist oder nicht~\autocite{GoogleTextClassification}

Im Kapitel \ref{chap:text-based-classification} wird die Text-basierte Klassifizierung der Rechnungen weiter verfolgt.

Die beiden Vorgehen zur Klassifizierung werden anhand der knapp 24500 bereits bei der AXA eingereichten Rechnungen getestet. Um dies zu ermöglichen, wurden die Rechnungen aus dem System der AXA exportiert und in die oben genannten Klassen eingeteilt. Dabei wurde der Datensatz auf 17323 Rechnungen reduziert. Etwas mehr als 7000 Rechnungen hatten mehr als eine Seite. Aus diesem Grund konnten diese Rechnungen mit den vorhandenen Informationen nicht eindeutig einer Klasse zugewiesen werden. Eine manuelle Klassifizierung würde für den Umfang dieses Experiments einen zu grossen Arbeitsaufwand darstellen.

Nach der Einteilung in die vier Klassen ist festzustellen, dass die 17323 Rechnungen eine sehr unregelmässige Verteilung aufweisen (vgl. Abbildung. \ref{class-distribution}). Es ist wichtig, diesem Umstand während dem Training eines Modells Rechnung zu tragen. Ansonsten würde die Voraussage des Modells zu Oft in der Klasse \enquote{Andere} resultieren, da mit Abstand am meisten Rechnungen dieser Klasse vorhanden sind. Diese Problematik kann auf diverse Arten angegangen werden. In dieser Arbeit wird während dem Training die Funktion, welche das Modell trainiert, die sogenannte loss function, durch eine Gewichtung aufgrund der Klassenverteilung diesem Umstand Rechnung tragen~\autocite{Buda2018}.

\begin{figure}[h]
    \captionsetup{width=.8\linewidth}
    \caption{Ungleichverteilung der Klassen innerhalb des Trainingsdatensatzes}
    \label{class-distribution}
    \centering
    \begin{tikzpicture}
        \begin{axis}[
            ybar,
        	ylabel=Anzahl Rechnungen,
        	enlargelimits=0.05,
            symbolic x coords={Sportverein,Fitness,Optiker,Andere},
            y tick label style={/pgf/number format/fixed},
            scaled y ticks=false,
            xtick=data,
            nodes near coords,
            nodes near coords align={vertical},
        ]
            \addplot 
        	    coordinates {(Sportverein, 681) (Fitness, 1432) (Optiker, 2215) (Andere, 12995)};
        \end{axis}
    \end{tikzpicture}
\end{figure}

\subsubsection{Bild-basierte Rechnungsklassifizierung}

% http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.414.9846&rep=rep1&type=pdf

Analog der Klassifizierung von Objekten auf Fotos, wie dies von diversen künstlichen Intelligenzen gemacht wird, ist es auch denkbar, Rechnung mit Hilfe diesem Bild-basiertem Vorgehen zu klassifizieren.

Auf dem Machine Learning Blog \enquote{Towards Data Science} beschreiben und vergleichen diverse Autoren verschiedenste Modelle im Bereich der Computer Vision. Der Blog bietet einen guten Überblick über die aktuellen Methoden zur Klassifizierung von Bildern. So werden im Juli 2017 die Residual Networks (kurz ResNet), entwickelt von \textcite{He2015}, als die bahnbrechendse Eingabe beim ImageNet LSVRC Wettbewerb\footnote{Die ImageNet Large Scale Visiual Recognition Competition (LSVRC) ist ein Wettbewerb der ImageNet Organisation, bei welcher hunderte Data Scientists ihre Modelle im Bereich der Computer Vision vergleichen. TODO: Quelle} der letzten Jahre bezeichnet~\autocite{Fungg2017ResNet}. Im September 2018 beschreibt \textcite{SHTsuang2018Inception} das InceptionV4 Netzwerk von Google, welches vom GoogLeNet abgeleitet und mit den Ideen aus dem ResNet erweitert wurde. Das Modell erzielt noch bessere Resultate als das ResNet selbst. Im gleichen Artikel wird auch das Inception-ResNet-V2 vorgestellt, welches im Vergleich zum InceptionV4 Netzwerk schneller trainiert werden kann und zugleich etwas bessere Resultate erzielt. 

In einem Blog Post auf dem Google AI Blog präsentieren Forscher aus dem Google Brain Team das NASNet. NASNet ist ein Modell zur Klassifizierung von Bildern, welches durch die Anwendung von Machine Learning designed wurde~\autocite{GoogleNasNet}. Unter dem Codename AutoML publiziert das Google Brain Team einen Ansatz, bei welchem ein Neuronales Netzwerk ein anderes erstellt - eine künstliche Intelligenz, welche eine neue künstliche Intelligenz schafft. Mit diesem Ansatz kann das sehr aufwendige Design eines Neuronalen Netzwerks vereinfacht beziehungsweise automatisiert werden~\autocite{GoogleAutoML}.

\begin{wrapfigure}{r}{0.6\textwidth} 
    \caption{Vergleich des vom Google Brain Team präsentierten NASNet mit bestehenden Netzwerken zur Klassifizierung von Bildern des ImageNet Datensatzes. Es wird die Treffergenauigkeit, der Prozentsatz richtig Klassifizierter Bilder der Gesamtheit aller Bilder, der Anzahl benötigter Operationen, sprich die Komplexität des Netzwerks, gegenübergestellt.}
    \label{nasnet-comparision}
    \centering
    \includegraphics[width=0.55\textwidth]{graphics/nasnet-comparision.jpg}
    \caption*{Quelle: \textcite{GoogleNasNet}}
\end{wrapfigure}
Als Teil des selben Blog Posts, in welchem das NASNet präsentiert wird, vergleichen die Forscher von Google das Modell mit anderen Netzwerken, wie dem ResNet und dem Inception-ResNet-V2. Der Abbildung \ref{nasnet-comparision} ist zu entnehmen, dass das vom Google Brain Team präsentierte NASNet, in der \enquote{medium} Ausprägung, trotz reduzierter Anzahl an benötigter Operationen, sprich reduzierter Komplexität, verbesserte Treffergenauigkeit als die bisherigen Netzwerke erzielt. In der \enquote{large} ausprägung kann das NASNet durch eine erhöhte Komplexität eine noch bessere Treffergenauigkeit erzielen~\autocite{GoogleNasNet}.

% ResNet Arxiv: https://arxiv.org/abs/1512.03385
% ResNet: https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035
% DRM Arxiv: https://arxiv.org/abs/1512.03385
% DRN: https://towardsdatascience.com/review-drn-dilated-residual-networks-image-classification-semantic-segmentation-d527e1a8fb5
% InceptionV4: https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc

% NASNet: https://ai.googleblog.com/2017/11/automl-for-large-scale-image.html

% NASNet example https://www.tensorflow.org/hub/tutorials/image_retraining

% AutoML: https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html


% TODO: Dilated Residual Network beschreiben: Veränderung der Convolutions in einem ResNet zu einem Grid anstelle der herkömmlichen convolution.

Im folgenden wird das ResNet, das Inception-ResNet-V2 sowie das NASNet large Netzwerk angewendet, um die bisher bei der AXA eingereichten Rechnung zu klassifizieren.

Um Bilderkennungsmodelle mit Millionen von Parametern zu trainieren, werden viele Trainingsdaten und eine enorme Kapazität an Rechenleistung benötigt. Das Konzept des Transfer Learning bietet eine Möglichkeit, diese beiden Problematiken zu Umgehen und dabei nur wenig Treffergenauigkeit einzubüssen. Beim Transfer Learning wird ein Modell mit Hilfe eines Datensatzes trainiert, welcher nichts mit der eigentlichen Problemstellung zu tun hat. Das trainierte Modell wird dann mit den für die Problemstellung relevanten Daten weiter trainiert, sogenanntes Fine Tuning~\autocite{TensorflowImageRetraining, TDSTransferLearning}.

Um die Rechnungen zu klassifizieren wird Transfer Learning angewendet, indem das Training der genannten Modelle auf dem ImageNet Datensatz als Grundlage verwendet wird.

Nach dem Training auf dem ImageNet Datensatz wird werden die letzten Schichten des Netzwerks, jene die für die Klassifizierung zuständig sind, durch ein neues Klassifizierungsnetzwerk ersetzt. Dadurch wird der Trainingseffekt durch den ImageNet Datensatz beibehalten und die Klassifikation so angepasst, dass sie die Einteilung in die vier vorliegenden Klassen erlaubt.

Das Klassifizierungsnetzwerk (vgl. Abbildung \ref{image-classification-model}), welches zur Anwendung kommt, besteht aus einem Convolution Layer sowie drei Fully Connected Layer. Zwischen den Fully Connected Layern sind zwei Dropout Layer zur reduzierung des Overfitting\footnote{Overfitting bezeichnet das Auswendiglernen eines Modells. Das Modell klassifiziert während dem Training sehr gut, da es alle Beispiele Auswendig lernt. Bei neuen Daten macht das Modell aber viele Fehler, da das Modell diese Daten nicht auswendig lernen konnte. TODO bessere beschreibung \& Quelle} eingeschoben, um ein Overfitting zu verhindern.

\begin{wrapfigure}{L}{0.4\textwidth} 
    \caption{Neuronales Netzwerk, welches bei der Text-basierten Klassifizierung zur Anwendung kommt. Der Input aus dem Wörterbuch wird durch zwei Fully Connected und einem Dropout Layer in einen One Hot Encoded Output transformiert, der die erkannte Klasse repräsentiert.}
    \label{image-classification-model}
    \centering
    \includegraphics[width=0.2\textwidth]{graphics/image-classification-results/model.pdf}
\end{wrapfigure}

Die genannten Modelle werden mit 80\% der vorhandenen Daten trainiert, die übrigen 20\% werden benötigt, um den Trainingsfortschritt zu prüfen. Mit den 20\% Testdaten soll ein allfälliges Overfitting erkannte werden.

Die Abbildung \ref{image-class-results} zeigt das Training der genannten Modelle. \ref{image-class-results:a} und \ref{image-class-results:b} zeigen die Treffergenauigkeit respektive das sogenannte loss\footnote{TODO: loss beschreiben} während dem Training. Während dem Training steigt die Treffergenauigkeit stetig an und das loss sinkt stetig. Dies ist ein gutes Zeichen. \ref{image-class-results:c} und \ref{image-class-results:d} zeigen die Treffergenauigkeit respektive das loss bei der Anwendung des Modells auf den Testdaten. Die Treffergenauigkeit hat nach der Epoche\footnote{TODO: Epoche beschreiben...} 13 bereits das Maximum erreicht. In den folgenden Epochen schwankt die Treffergenauigkeit stark und erhöht sich nicht mehr. Nach nur etwa 5 Epochen Training steigt das loss für die Testdaten an. Daraus kann abgeleitet werden, dass die Modelle beginnen zu Overfitten.

--> Kein Overfitting sondern schlechter optimizer....

\begin{figure}[ht] 
  \captionsetup{width=.8\linewidth}
  \caption{Statistiken aus dem Training der Bild-basierten Klassifikation von Rechnungen mit den ResNet, Inception-ResNetV2 und NASNet Netzwerken.}
  \label{image-class-results} 
  \includegraphics[width=0.5\textwidth]{graphics/image-classification-results/legend.pdf}
  \begin{subfigure}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=0.75\linewidth]{graphics/image-classification-results/acc.pdf} 
    \caption{Treffergenauigkeit} 
    \label{image-class-results:a} 
    \vspace{2ex}
  \end{subfigure}%% 
  \begin{subfigure}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=0.75\linewidth]{graphics/image-classification-results/loss.pdf} 
    \caption{loss} 
    \label{image-class-results:b} 
    \vspace{2ex}
  \end{subfigure} 
  \begin{subfigure}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=0.75\linewidth]{graphics/image-classification-results/val_acc.pdf} 
    \caption{Treffergenauigkeit bei den Testdaten} 
    \label{image-class-results:c} 
  \end{subfigure}%%
  \begin{subfigure}[b]{0.5\linewidth}
    \centering
    \includegraphics[width=0.75\linewidth]{graphics/image-classification-results/val_loss.pdf} 
    \caption{loss bei den Testdaten} 
    \label{image-class-results:d} 
  \end{subfigure}
  \centering
\end{figure}

\todo[inline]{Update graphics \& legend with NASNet Results, also revisti the paragraph above, whether it holds true for NASNet}

Die einzelnen Modelle zeigen eine Treffergenauigkeit von 88.1\% (ResNet, Epoche 4), 88.4\% (Inception-ResNet-V2, Epoche 9) beziehungsweise xx\% (NASNet, Epoche N).

\todo[inline]{Dropout beschreiben, Wahl dieses Modells begründen}


Optimierungspotential:

- https://towardsdatascience.com/deep-learning-performance-cheat-sheet-21374b9c4f45

\textbf{Data augmentation}

https://medium.com/nanonets/how-to-use-deep-learning-when-you-have-limited-data-part-2-data-augmentation-c26971dc8ced


\textbf{Local mimimum through Adam optimizer}

https://towardsdatascience.com/estimating-optimal-learning-rate-for-a-deep-neural-network-ce32f2556ce0


\textbf{Experiment with batch size and number of epochs}

\textbf{Generate Network using AI (or just the optimizer)}

ENAS: https://github.com/carpedm20/ENAS-pytorch
Neural Architecture Search with Reinforcement Learning: https://arxiv.org/abs/1611.01578
Neural Optimizer Search with Reinforcement Learning: https://arxiv.org/abs/1709.07417

\textbf{Weight penalty L1 and L2}

Improve performance and reduce overfitting -> Keeps weights in NN small
-> Have a look at the trained model, are there huge weights? If so, highlight this as a problem




\subsubsection{Text-basierte Rechnungsklassifizierung}
\label{chap:text-based-classification}

Werden die Rechnungen nicht als Bilder angesehen sondern wird der auf Ihnen aufgedruckte Text als zentraler Aspekt angesehen, so liegt die Klassifizierung der Rechnung aufgrund dieses Textes nahe. Um die Rechnungen allerdings aufgrund des Textes zu Klassifizieren, muss dieser zuerst aus den Bildern der Rechnungen extrahiert werden. Mit Hilfe von Tesseract OCR wird der Text aus den Bildern extrahiert.

Nach dem Extrahieren des Textes aus den Rechnungen wird als erstes ein Wörterbuch gebildet, welches das WordEmbedding \todo{Referenz auf Erklärungskapitel} ermöglicht. Das WordEmbedding dieses Wörterbuchs ist sehr einfach gehalten und erlaubt keine Rückschlüsse auf die Bedeutung der Wörter aufgrund des resultierenden Vektors.

Das Wörterbuch wird erstellt, indem der Text erst in Kleinbuchstaben umgewandelt und anschliessend bei Leerzeichen getrennt wird. Es werden alle Stopp-Wörter wie \enquote{und}, \enquote{ein} und \enquote{diese} entfernt, da aus ihnen keine Information gewonnen werden kann. Es werden die häufigsten Wörter ermittelt, zu welchen sich das Wröterbuch eine eindeutige Zahl hält. Das Wörterbuch hält sich nur die häufigsten Wörter um die Komplexität gering zu halten.

Nach dem Wörterbuch wird ein Klassifizierungsmodell erstellt. Input dieses Netzwerks ist ein Vektor in der Länge der Anzahl Wörter im Wörterbuch. Pro Wort wird in diesem Vektor die präsenz des Wortes innerhalb einer Rechnung angegeben. Nach dem Input folgt zwei Hidden Layer. Ein Fully Connected Layer, welcher durch einen Dropout Layer mit dem Fully Connected Output Layer verbunden ist (vgl. Abbildung \ref{text-classification-model}). 

\begin{wrapfigure}{r}{0.4\textwidth} 
    \caption{Neuronales Netzwerk, welches bei der Text-basierten Klassifizierung zur Anwendung kommt. Der Input aus dem Wörterbuch wird durch zwei Fully Connected und einem Dropout Layer in einen One Hot Encoded Output transformiert, der die erkannte Klasse repräsentiert.}
    \label{text-classification-model}
    \centering
    \includegraphics[width=0.2\textwidth]{graphics/text-classification/model.pdf}
\end{wrapfigure}


TODO




Die Text-basierte Klassifizierung hat mit XX\% eine höhere Treffergenauigkeit erreicht als die Bild-basierte Klassifizierung. Dennoch gibt es auch bei diesem Vorgehen noch Optimierungspotential.

\textbf{OCR Fehler}

Die Ergebnisse des Optical Character Recognition System sind teilweise sehr dürftig. Um die Resultate dieses Zwischenschritts zu verbesseren, sieht der Autor folgende Optionen.

\begin{itemize}
    \item Es könnte versucht werden, dass LSTM Modell, welches dem Tesseract OCR System zugrunde liegt, auf die Rechnungen zu trainieren. Das OCR System kann durch Training mit Schriftzügen und Buchstaben, auf welche das System bisher nicht Trainiert wurde, einiges an Treffergenauigkeit gewinnen. Das System sollte aus diesem Grund auf die gängigsten Schriften der Rechnungen trainiert werden\~{TesseractTraining}.
    \item Aktuell wurde das OCR System mit den Sprachen Deutsch, Englisch, Französisch und Italienisch instruiert. Nach dem ersten Lauf mit diesen vier Sprachen könnte versucht werden, mit einem KI-Modell die Sprache zu erkennen. Anschliessen könnte das OCR System mit nur dieser Sprache erneut verwendet werden. Somit könnten beispielsweise falsche diakritische Zeichen durch eine Körnung des Bildes vermindert werden. Auch erlaubt dieses Vorgehen dem OCR System die verbesserte Erkennung durch dem System bekannte Wörter.
    \item Die Ergebnisse aus dem OCR Schritt könnten durch ein Rechtschreibe- und Grammatikkorrektur-Modell verbessert werden. \todo{Referenz auf Einleitungskapitel}
\end{itemize}

\textbf{Verbessertes WordEmbedding}

Anstelle des aktuell verwendeten, einfachen Word Tokenizer könnte ein komplexeres WordEmbedding\todo{Referenz auf Einleitungskapitel} angewendet werden. Jüngste Forschungen zeigen, dass auch in diesem Bereich dank Transfer Learning gute Ergebnisse erzielt werden können. Beispielsweise wurde im Oktober 2018 mit BERT\footnote{Bidirectional Encoder Representations from Transformers, kurz BERT, ist ein Modell zur repräsentation von natürlicher Sprache. Das Modell des Google Reasearch Team bricht viele bisherige Rekorde bei Natural Language Processing Wettbewerben~\autocite{Devlin2018}} ein sehr erfolgreiches Modell im Bereich des Natural Language Processing publiziert, welches als Grundlage für das Transfer Learning dienen kann~\autocite{Devlin2018}.

\todo[inline]{
Klassifizierung von Rechnungen

Evtl. verschiedene Ansätze

- OCR -> (SpellCorrection ->) WordEmbedding -> classification

- Pixel -> classification

- OCR -> (SpellCorrection ->) InformationExtraction -> classification

Bewertung der Ergebnisse
}

\todo[inline]{Dropout und dilating beschreiben}

\subsection{Teil 2 - Informationsextraktion}

% Massive comparision of object detection models: https://medium.com/@jonathan_hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359
% Do these results hold true for our "special" case of papaer region detection?

% https://rectlabel.com

\subsection{Ausblick}

Mägliches Potential

Rotations-Erkennung (Verbessert evtl. OCR, etc., see 5a6af27e0cf2ab51c3ec3c70.pdf.png for OCR result)

Filter out training data of low quality images...

Kontrast extrem wichtig für OCR, mehr als Körnung und Schärfe....

Rotation hat bei OCR klassifizierung einen starken einfluss...

Extrem viele QualiCert Belege, diese aber oft handschriftlich, IE ist wohl schwer
