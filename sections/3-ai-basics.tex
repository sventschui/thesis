% \section{Vorgehen und Methodik}

%#############################
% Forschungsstand zur künstlichen Intelligenz
%#############################
\section{Künstliche Intelligenz: Grundlagen und Ansätze in der Praxis}
\label{chap:ai}

% \todo[inline, color=igloo]{Vorschlag: Hier könntest Du mit dem Begriff KI beginnen und die Problematik ansprechen, dass zwar viele davon sprechen, aber (falls überhaupt) nur wenige wissen, was darunter zu verstehen ist. Vieles, was heute angeboten wird, basiert auf ML-Ansätzen, wie z.B. und dann kannst Du best practices aufweisen.}

Die künstliche Intelligenz ist ein in der Literatur oft diskutiertes Themengebiet. Bereits 2009 geben \textcite{Russell2009} auf über 1000 Seiten einen noch immer aktuellen und sehr umfangreichen Überblick. Weiter vertiefen die beiden Autoren viele Teilgebiete der künstlichen Intelligenz und erläutern grundlegende Konzepte ausführlich.

% Einen etwas mathematischeren Überblick über das Thema künstliche Intelligenz geben \textcite{Goodfellow2016}. Die Diskussion reicht von den absoluten Grundlagen, der linearen Algebra, bis hin zu Deep Generative Models, eine fortgeschrittene Anwendung der künstlichen Intelligenz~\autocite{Goodfellow2016}.

Es kann gesagt werden, dass in der Grundlagenforschung zur künstlichen Intelligenz bereits viele Forschungsergebnisse vorliegen. Es werden etliche, etablierte und experimentelle, Techniken diskutiert und täglich weiterentwickelt. Zur Automatisierung eines Geschäftsprozesses und somit für die Entwicklung eines Prototypen für die AXA Gesundheitsvorsorge stehen unzählige Möglichkeiten zur Verfügung.

Dieses Kapitel gibt ein Überblick über das Themengebiet der künstlichen Intelligenz. Es werden für diese Arbeit relevante Techniken, Konzepte und Begriffe erläutert. Es werden Konzepte und Metriken vorgestellt, welche verwendet werden, um eine künstliche Intelligenz zu bewerten. Zum Schluss wird aufgezeigt, wie eine künstliche Intelligenz modelliert und die finale Architektur entsteht.

\subsection{Neuronale Netzwerke}
\label{chap:neuron}

Abgesehen von Rechenaufgaben sind Menschen leistungsfähiger als Computer. Wir sind beispielsweise in der Lage, Gesichter zu erkennen oder in einem dunklen Raum Personen anhand Ihrer Stimme zu identifizieren. Der interessanteste Unterschied des menschlichen Gehirns zu einem Computer ist der Fakt, dass unser Gehirn lernt, ohne eine Softwareaktualisierung zu erhalten. Wir brauchen nicht erst eine neue Software, um das Fahrradfahren zu erlernen~\autocite{Krogh2008}. Doch wie funktioniert das?

Die Berechnungen des menschlichen Gehirn werden durch hoch vernetzte Neuronen gemacht. Dabei interagieren die Neuronen mit Stromimpulsen durch die neuronale Verkabelung, bestehend aus Nervensäulen, Synapsen und Zellfortsätzen. 1943 modellierten McCulloch und Pitts Neuronen als Schalter, welche aufgrund der eingehenden Signale ein- oder ausgeschaltet werden. Die Gewichtung der eingehenden Signale sind dabei die Synapsen. Aus diesem Modell entstand das Konzept von neuronalen Netzwerken~\autocite{Krogh2008}.

Ein Neuron wurde von McCulloch und Pitts als eine Threshold Unit (vgl. Abbildung \ref{krogh:a}) modelliert, welche Eingabewerte anderer Units oder externer Quellen erhält. Die Threshold Unit erhält $N$ Eingangssignale $x_1, ..., x_N$. Diese Eingangssignale werden mit dem zugehörigen Gewicht $w_1, ..., w_N$ multipliziert und schlussendlich summiert. Dieses Summenprodukt kann auf zwei verschiedene Arten die Aktivierung des Neurons auslösen. Zum einen kann das Neuron je nach Erreichung eines Gewissen Threshold ($t$) mit $0$ oder $1$ aktiviert werden. Andererseits kann eine Aktivierungsfunktion verwendet werden. Das Modell von McCulloch und Pitts in Abbildung \ref{krogh:a} zeigt einen kontinuierlichen Sigmoiden $\sigma(x) = \frac{1}{1+e^{-x}}$ (rote Linie) als mögliche Aktivierungsfunktion~\autocite{Krogh2008}. 

%\begin{wrapfigure}{l}{0.6\textwidth} 
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Modell eines Neurons nach McCulloch und Pitts}
    \label{krogh:a}
    \centering
    \includegraphics[width=0.5\textwidth]{graphics/krogh/krogh_neural-network.png}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{Krogh2008}}
%\end{wrapfigure}
\end{figure}

Neuere Modelle, welche heute in neuronalen Netzwerken zur Anwendung kommen, verwenden stets eine Aktivierungsfunktion anstelle eines Thresholds. Der Begriff Threshold Unit ist aus diesem Grund nicht mehr geläufig. Die Rectified Linear Unit (kurz ReLU) Aktivierungsfunktion ist aktuell die weit verbreitetste. Die ReLU Aktivierungfunktion bedient sich selbst auch an einem Threshold. Sie begrenzt das Summenprodukt aus den Eingangssignalen und Gewichten gegen unten auf 0 und wird als $f(x) = \textnormal{max}(0, x)$ definiert. Im Gegensatz zur Aktivierung aufgrund eines Thresholds kann der Ausgabewert somit einen kontinuierlichen Wert von 0 bis $\infty$ annehmen. Im Gegensatz zu einem kontinuierlichen Sigmoiden hat die ReLU Aktivierungsfunktion nicht nur den Vorteil, dass sie weniger rechenintensiv ist, sondern dass das neuronale Netzwerk bis zu sechs mal effektiver trainiert werden kann. Der Nachteil dabei ist, dass durch ein zu schnelles Training eines neuronalen Netzwerks Neuronen mit der ReLU Aktivierungsfunktion Gewichte erlernen können, durch welche sie immer 0 ausgeben. Solche Neuronen werden als tote Neuronen bezeichnet. Durch eine kleinere Learning Rate\footnote{Die Learning Rate definiert, wie stark die trainierbaren Parameter (beispielsweise die Gewichte) eines Neurons nach jedem Trainingsdurchgang angepasst werden. Die Learning Rate bestimmt somit die Geschwindigkeit, mit welcher ein neuronales Netzwerk lernt~\autocite{Goodfellow2016}.} kann dieses Phänomen vermindert werden~\autocite{cs231NN}.

Neben den trainierbaren Gewichten wurden neuere Modelle von Neuronen auch um einen trainierbaren Bias erweitert. Dieser Bias wird zum Summenprodukt der Eingabesignale und der Gewichte addiert, bevor dieses der Aktivierungsfunktion übergeben wird. Ist die Aktivierungsfunktion $f$ gegeben, so wird der Ausgabewert eines Neurons als $f((\sum_{i}^{n}{w_{i}x_{i}})+b)$ definiert~\autocite{cs231NN}.

Neuronale Netzwerke werden als eine Ansammlung von vernetzten Neuronen modelliert. Die Ausgabe eines Neurons fliesst als Eingabe in das nächste Neuron. Wichtig dabei ist, dass keine Schlaufen erlaubt sind, da dies in einer unendlichen Schlaufe resultieren würde. Die Neuronen sind nicht willkürlich angeordnet, sondern in Schichten organisiert. Für normale neuronale Netzwerke ist ein sogenannter Fully Connected Layer die verbreitetste Art von Schicht. Jedes Neuron einer solchen Schicht ist mit jedem Neuron aus der vorherigen Schicht verbunden. Die Neuronen dieser Schicht haben allerdings keine Verbindungen untereinander. Die Abbildung \ref{fig:cs231-nn} zeigt ein zweischichtiges neuronales Netzwerk mit drei Eingabewerten (rot), einer versteckten Schicht (englisch Hidden Layer) mit vier Neuronen (blau) und eine Ausgabe-Schicht mit zwei Neuronen (grün)~\autocite{cs231NN}.

%\begin{wrapfigure}{l}{0.6\textwidth} 
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Modell eines neuronalen Netzwerks mit zwei Fully Connected Layer}
    \label{fig:cs231-nn}
    \centering
    \includegraphics[width=0.4\textwidth]{graphics/cs231-nn.jpg}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{cs231NN}}
%\end{wrapfigure}
\end{figure}

Damit ein neuronales Netzwerk leistungsfähig werden kann, muss es ähnlich wie ein Mensch, erst lernen. Für das neuronale Netzwerk bedeutet Lernen, für die Gewichte und den Threshold geeignete Werte zu finden. Dieses computersimulierte Lernen, auch Machine Learning genannt, funktioniert dabei so, dass für die Gewichte der Verbindungen, sprich die Stärke der Synapsen, ein zufälliger Wert gewählt wird. Anschliessend wird eine Übungsaufgabe vom Netzwerk gelöst. Das Resultat des Netzwerks ist zu Beginn höchstwahrscheinlich falsch und die Gewichte im Netzwerk werden mit einem kleinen Schritt angepasst. Es werden dann immer weitere Aufgaben gelöst und die Gewichte entsprechend angepasst bis das Netzwerk die gewünschten Resultate liefert.
Dieses Training kann durch verschiedene Algorithmen implementiert werden. Einer solcher Algorithmus wird im Kapitel \ref{chap:backpropagation} beschrieben~\autocite{Krogh2008}.

Seit mehreren Jahren liefern neuronale Netzwerke bessere Resultate als klassische Techniken. Dabei werden neuronale Netzwerk vorwiegend für visuelle Aufgaben und immer häufiger auch zur Verarbeitung natürlicher Sprache verwendet~\autocite{Olah2014b}.

% \todo[inline]{Say a word on overfitting}

% \todo[inline]{Say something about learning strategies (supervised / unsupervised)}

\subsection{Tiefe neuronale Netzwerke}
\label{chap:deep-neural-nets}

Neuronale Netzwerke finden oftmals bei Klassifizierungsproblemen Anwendung. Dabei soll aufgrund bestimmter Eingabewerte eine Klasse bestimmt werden. Ein Beispiel dafür ist die Klassifizierung eines Säugetiers in die Klasse Hund oder Katze aufgrund ihrer Merkmale~\autocite{Krogh2008}.

Einfache Netzwerke von Neuronen können Klassifizierungsprobleme dann Lösen, wenn die Klassen linear separierbar sind. Die Abbildung \ref{krogh:b} veranschaulicht die lineare Separierung mit Hilfe einer Ebene in einem dreidimensionalen Raum. Die Ebene separiert die grünen und roten Punkte voneinander~\autocite{Krogh2008}.

%\begin{wrapfigure}{l}{0.4\textwidth} 
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Konzept der linearen Separierbarkeit}
    \label{krogh:b}
    \centering
    \includegraphics[width=0.4\linewidth]{graphics/krogh/krogh_plane.png}
    \caption*{Quelle: \textcite{Krogh2008}}
%\end{wrapfigure}
\end{figure}

Der Abbildung \ref{krogh:b} ist zu entnehmen, dass die Problemstellung im abgebildeten Fall, wie die meisten Klassifizierungsprobleme, nicht linear separierbar ist. Die roten und grünen Kreuze markieren dabei Punkte, welche auf der falschen Seite der Ebene liegen. Eine Klassifizierung durch ein einfaches Netzwerk von Neuronen würde die Klasse dieser Datensätze falsch vorhersagen~\autocite{Krogh2008}.

Um das Modell zur Klassifizierung zu verbessern, können zusätzliche Ebenen in den dreidimensionalen Raum eingesetzt werden. Durch eine weitere Ebene ist es dem Modell möglich, mehr Datensätze korrekt zu klassifizieren. Neue Ebenen werden mit neuen Schichten von Neuronen modelliert (vgl. Abbildung \ref{krogh:c}). Diese neuen Schichten, welche sich zwischen den Eingabe und Ausgabe Schichten befinden, werden versteckte Schichten (Hidden Layers) genannt. Ein Modell mit mindestens einer solcher versteckter Schicht wird als tiefes neuronales Netzwerk (Deep Neural Network) bezeichnet~\autocite{Krogh2008}.

% \begin{wrapfigure}{l}{0.4\textwidth} 
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Modell eines tiefen neuronalen Netzwerks mit einer versteckten Schicht}
    \label{krogh:c}
    \centering
    \includegraphics[width=0.4\linewidth]{graphics/krogh/krogh_deep-network.png}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{Krogh2008}}
%\end{wrapfigure}
\end{figure}

Mit immer mehr verfügbarer Rechenkapazität und immer mehr Daten steigt die Popularität tiefer neuronaler Netzwerke gegenüber traditionellen Lernalgorithmen wie der logistischen Regression. Je tiefer und breiter ein neuronales Netzwerk ist und je mehr Trainingsdaten zur Verfügung stehen, desto besser wird es eine Problemstellung lösen können (vgl. Abbildung \ref{scale-drives-ml-progress})~\autocite{MLYearning}.

% \begin{wrapfigure}{l}{0.4\textwidth} 
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Verhältnis der verfügbaren Daten und der Genauigkeit unterschiedlich grosser neuronaler Netze}
    \label{scale-drives-ml-progress}
    \centering
    \includegraphics[width=0.4\linewidth]{graphics/scale-drives-ml-progress.png}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{MLYearning}}
%\end{wrapfigure}
\end{figure}

Ein tiefes neuronales Netzwerk stellt neue Anforderungen an das Training. Ein Netzwerk mit versteckten Schichten kann nicht mehr auf eine analytische Weise trainiert werden. Aus diesem Grund wird ein komplexerer Lernalgorithmus benötigt. Ein solcher Algorithmus wird im Kapitel \ref{chap:backpropagation} erläutert~\autocite{Krogh2008}. 

Auch ist ein tiefes neuronales Netzwerk anfälliger auswendig zu lernen und birgt somit die Gefahr schlecht zu generalisieren. Dieses sogenannte Overfittig wird im Kapitel \ref{chap:overfitting} erläutert.

\subsection{Backpropagation}
\label{chap:backpropagation}

Da tiefe neuronale Netzwerke zu Komplex sind, um mit einem analytischen Ansatz trainiert zu werden, muss ein anderes Vorgehen gefunden werden. Das am meisten angewendete Vorgehen zum Training von tiefen neuronalen Netzwerken ist die sogenannte Backpropagation. Bei der Backpropagation werden zu Beginn zufällige Gewichte und Bias festgesetzt. Das Netzwerk löst mit diesen zufälligen Gewichten und Bias eine erste Übungsaufgabe. Die Abweichung vom erwarteten Resultat (der sogenannte Fehler) wird anschliessend quadriert. Ziel des Backpropagation ist es, diesen quadrierten Fehler zu minimieren. Dies wird erzielt, indem das Verfahren des steilsten Abstiegs, auch Gradientverfahren (englisch gradient descent), angewendet wird. Mit Hilfe dieses Verfahrens, zur Lösung allgemeiner Optimierungsprobleme aus der Numerik, werden nun die Gewichte und das Bias so angepasst, dass der quadrierte Fehler minimiert werden kann. Dieses Vorgehen wird mit weiteren Übungsaufgaben wiederholt, bis sich der quadrierte Fehler nicht mehr verändert~\autocite{Krogh2008}.

Bei der Backpropagation müssen einige Herausforderungen beachtet werden. So kann durch das Gradientverfahren nur ein lokales Minimum gefunden werden. Ob dieses lokale Minimum dem globalen Minimum entspricht, ist nicht bekannt. Das Ergebnis des Trainings ist damit von den zufällig gewählten Startwerten der Gewichte und Bias abhängig~\autocite{Krogh2008}.

Die grösste Problematik beim Trainieren von neuronalen Netzwerken, besonders von tiefen neuronalen Netzwerken, ist die Gefahr des sogenannten Overfitting oder Auswendiglernens~\autocite{Krogh2008}.

\subsection{Over- und Underfitting}
\label{chap:overfitting}

Eine Herausforderung der künstlichen Intelligenz beziehungsweise des Machine Learning ist es, auf zuvor unbekannten Daten gute Ergebnisse zu erzielen. Diese Fähigkeit wird als Generalisierung bezeichnet~\autocite{Goodfellow2016}.

Um eine Generalisierung sicherzustellen, wird ein Modell immer auf einem Trainingsdatensatz trainiert und auf einem Testdatensatz validiert. Ziel eines Modells ist es, die Fehler während dem Training (auch Bias genannt) zu minimieren und den Unterschied zwischen der Fehlerquote während dem Training und während dem Testen (auch Varianz genannt) möglichst klein zu halten. Die Nichterreichung dieser Ziele wird Over- respektive Underfitting genannt~\autocite{Goodfellow2016}.

Die Problematik des Underfitting wurde bereits bei der Einführung von tiefen neuronalen Netzwerken, im Kapitel \ref{chap:deep-neural-nets}, angeschnitten. Ein Modell, welches zu wenige Parameter hat, ist nicht in der Lage eine komplexe Problemstellung abzubilden. Das Modell hat somit einen hohes Bias (hohe Fehlerquote auf dem Trainingsdatensatz). In diesem Fall ist es wichtig, das Modell anzupassen. Eine Erhöhung der Anzahl Trainingsdatensätze hilft nicht, den Bias zu reduzieren~\autocite{MLYearning}.

Das sogenannte Overfitting, oder auch Auswendiglernen, bezeichnet die Problematik, dass sich ein Modell aufgrund zu vieler Parameter bei zu wenig Trainingsdaten zu stark an diese Trainingsdaten anpasst. Das Modell kann die Trainingsdaten mit annähernd 100\% Trefferquote Beurteilen, hat also ein kleines Bias. Soll das Modell dann aber einen neuen Datensatz beurteilen, so sinkt die Trefferquote erheblich. Das Modell hat eine hohe Varianz und ist nicht in der Lage das gelernte zu generalisieren~\autocite{MLYearning, Krogh2008}.

Die Problematik des Overfitting ist aus der Mathematik bekannt. Hat eine Funktion zu viele freie Parameter, so passt sie sich zu stark an die vorgegebenen Punkte an. Die Abbildung \ref{krogh:d} veranschaulicht diese Problematik anhand von Graphen von Funktionen, welche 8 Punkte fitten sollen. Der grüne Graph ist ein Beispiel des Underfitting. Er hat zu wenige Parameter, um eine tiefe Abweichung zu erreichen. Der pinke Graph zeigt ein Beispiel eines Overfitting. Mit vielen Parametern vermag der Graph alle Punkte perfekt zu schneiden. Die vielen extremen Wendepunkte deuten aber darauf hin, dass der Graph neue Punkte mit hoher Wahrscheinlichkeit nicht schneiden würde. Der blaue Graph gilt als Beispiel für ein gutes Fitting. Der Graph ist nahe an den Punkten, ohne dabei extreme Wendepunkte haben zu müssen~\autocite{Krogh2008}.

% \begin{wrapfigure}{l}{0.4\textwidth} 
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Over- und Underfitting dargestellt anhand von Graphen von Funktionen}
    \label{krogh:d}
    \centering
    \includegraphics[width=0.5\linewidth]{graphics/krogh/krogh_overfitting.png}
    \vspace*{0.2cm}
    \caption*{Quelle: \textcite{Krogh2008}}
%\end{wrapfigure}
\end{figure}

Während die Problematik des Overfitting aus anderen Bereichen bereits bekannt ist, scheinen neuronale Netzwerke besonders anfällig für eine solche Überparametrierung. Würden wir ein Modell entwickeln, welches anhand 20 Merkmalen (20 Eingabewerte) mit Hilfe einer verstecken Schicht von 10 Neuronen erkennen soll, ob es sich um einen Hund oder eine Katze handelt, so würden 221 Parameter geschaffen. Jeder der 20 Eingabewerte wird durch ein Gewicht mit den 10 Neuronen aus der versteckten Schicht verbunden ($10 * 20 = 200$ Parameter). Jedes dieser Neuronen hat einen Bias (10 Parameter) und ist mit dem Ausgabeneuron verknüpft (10 Parameter). Das Ausgabeneuron selbst hat auch wieder einen Bias (1 Parameter). Wird dieses Modell mit 221 Parametern nun mit Hilfe von nur 100 Trainingsdatensätzen trainiert, so kann es diese problemlos auswendig lernen. Das Modell kann auf neuen Datensätzen nicht oder nur schlecht generalisieren und wird somit eine hohe Varianz aufweisen~\autocite{Krogh2008}.

Um ein solches Overfitting zu verhindern stehen diverse Techniken zur Verfügung. Eine beliebte Regularisierungstechnik ist es, eine sogenannte Dropout Schicht in das Netzwerk einzubringen. Diese Dropout Schicht deaktiviert während dem Training zufällige Neuronen. Dies hat zur Folge, dass während dem Training Teile des Netzwerks trainiert werden\footnote{Die genaue Funktionsweise einer Dropout Schicht ist für diese Arbeit nicht relevant, kann aber bei Bedarf in \textcite{Goodfellow2016} nachgelesen werden.}~\autocite{Goodfellow2016}.

Um Over- respektive Underfitting zu erkennen, ist es wichtig, ein neuronales Netzwerk an Daten zu testen, welche nicht zum Training verwendet wurden~\autocite{Krogh2008}.

\subsection{Convolutional Neural Network}
\label{chap:cnn}

Convolutional Neural Network (kurz CNN) funktionieren ähnlich wie normale neuronale Netzwerke. Sie bestehend ebenfalls aus Neuronen mit trainierbaren Gewichten und Bias. Convolutional Neural Networks machen eine Annahme zu ihren Eingabewerten. Sie sind speziell auf Bilder ausgelegt. Durch diese Annahme können gewisse Verhalten direkt in die Architektur einprogrammiert werden. Dadurch kann die Anzahl trainierbarer Parameter gegenüber normalen neuronalen Netzwerken reduziert und die Performance erhöht werden~\autocite{CNN}.

Die Eingabe in ein Convolutional Neural Network ist ein dreidimensionaler Vektor im Format Format Breite x Höhe x 3. Dieser Vektor hält die rohen Pixeldaten des Bildes. Ein Bild in einer Auflösung von 32x32 Pixeln wird durch einen Vektor der Grösse 32x32x3 repräsentiert. Die dritte Dimension, auch Tiefe genannt, hält die Farbinformationen eines Pixels im RGB Format~\autocite{CNN}.

Convolutional Neural Networks bestehen hauptsächlich aus den folgenden drei verschiedenen Typen von Schichten~\autocite{CNN}:

\begin{itemize}
    \item \textbf{Convolutional Layer}: Berechnen Ausgabewerte aufgrund von Verbindungen zu Ausschnitten aus der vorhergehenden Schicht, sprich Ausschnitten aus dem Bild, welches als Eingabewert verwendet wird.
    \item \textbf{Pooling Layer}: Reduziert den mehrdimensionalen Vektor aus der vorhergehenden Schicht entlang der räumlichen Dimensionen (Breite und Höhe).
    \item \textbf{Fully Connected Layer}: Ein Fully Connected Layer, wie er aus dem normalen neuronalen Netzwerk bekannt ist.
\end{itemize}

\textbf{Convolution Layer}

\nopagebreak

Ein Convolution Layer besteht aus mehreren, trainierbaren Filtern. Diese Filter beziehen sich auf einen räumlich (Breite und Höhe) kleinen Teil des Eingabe-Bildes respektive des Eingabe-Vektors. Die Filter haben die gleiche Tiefe (Grösse der dritten Dimension) wie der Eingabe-Vektor. Ein Filter eines Convolutional Neural Network könnte beispielsweise die Grösse 5x5x3 aufweisen. In diesem Fall ist der Filter mit einem 5x5 Pixel grossen Ausschnitt des Eingabe-Vektors verknüpft. Dieser Filter wandert horizontal und vertikal über den Eingabe-Vektor. Dabei wird jeweils das Skalarprodukt der Werte des Filters und der Werte des Eingabe-Vektors berechnet. Die Skalarprodukte, welche so an verschiedenen Positionen des Eingabe-Vetkors berechnet werden, bilden eine zweidimensionalen Aktivierungs-Vektor. Während dem Training erlernt das Netzwerk so Filter, welche durch bestimmte visuelle Merkmale (Kanten, Ecken, Häufungen von Farben) aktiviert werden. Jeder Convolution Layer hat mehrere solche Filter, damit das Netzwerk auf mehrere visuelle Merkmale reagieren kann. Pro Filter entsteht ein zwei-dimensionaler Aktivierungs-Vektor, welche gestapelt werden und dadurch den drei-dimensionalen Ausgabe-Vektor ergeben. Die Abbildung \ref{fig:conv:vis} veranschaulicht dieses Konzept. Auf der linken Seite ist der Eingabe-Vektor in blau dargestellt. Auf diesem Vektor wird der in rot dargestellte Filter angewendet. Dieser Filter deckt einen kleinen räumlichen Teil aber die gesamte Tiefe des Bildes ab. Die Aktivierung des Filters wird im grünen Ausgabe-Vektor abgelegt~\autocite{CNN}.

%\begin{figure}[h!]
%    \captionsetup{width=.9\linewidth}
%    \caption{Eingabe-Vektor, Filter und Ausgabe-Vektor eines Convolution Layer}
%    \label{fig:cnn:conv}
%    \centering
%    \includegraphics[width=0.4\textwidth]{graphics/cnn-conv.jpg}\\
%    \caption*{Quelle: \textcite{CNN}}
%\end{figure}

\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Visualisierung eins Convolution Layer}
    \label{fig:conv:vis}
    \centering
    \includegraphics[scale=0.49]{graphics/cnn-visual.pdf}\\
    \vspace*{0.3cm}
    \caption*{Quelle: In Anlehnung an \textcite{CNN}}
\end{figure}

Die Anzahl der Filter und die Art wie sich ein Filter über die räumlichen Dimensionen des Eingabe-Vektors bewegt, kann durch Hyperparameter\footnote{Als Hyperparameter werden jene Parameter eines Machine Learning Modells bezeichnet, welche nicht während dem Training gelernt, sondern von aussen in das Modell hineingegeben werden. Die Hyperparameter können als Konfiguration eines Modells verstanden werden~\autocite{DesignML}.} konfiguriert werden. Mit der Anzahl an Filtern kann konfiguriert werden, wie viele verschiedene visuelle Merkmale der Convolution Layer erkennen kann. Die Anzahl an Filtern bestimmt die Tiefe des Ausgabe-Vektors. Die Abbildung \ref{fig:conv:vis} zeigt einen Convolution Layer mit zehn Filtern. Die dritte Dimension des Ausgabe-Vektor hat dadurch die Grösse zehn~\autocite{CNN}.

Die Art wie sich ein Filter über die räumlichen Dimensionen bewegt, kann durch das sogenannte Zero-Padding und den Stride konfiguriert werden. Das Zero-Padding sagt aus, wie viele zusätzliche Neuronen um den Eingabe-Vektor herum gelegt werden sollen. Das Zero-Padding ermöglicht, dass die Filter auch visuelle Merkmale an den Rändern des Eingabe-Vektors erkennen können. Der Stride bestimmt die Anzahl Neuronen, um welche der Filter nach jeder Anwendung verschoben wird. In Abbildung \ref{fig:conv:vis} ist ein Beispiel eines Convolution Layer mit einem Zero-Padding von eins und einem Stride von zwei zu sehen. Durch diese Hyperparameter und die Grösse der ersten beiden Dimensionen des Eingabe-Vektors wird die Grösse der ersten beiden Dimensionen des Ausgabe-Vektors bestimmt. Bei der Wahl des Zero-Padding und des Strides muss darauf geachtet werden, dass die Filter genau auf den Eingabe-Vektor passen. Würde im Beispiel, welches in Abbildung \ref{fig:conv:vis} ersichtlich ist, ein Stride von drei anstatt zwei gewählt werden, so könnte der Filter nur 1.33 mal verschoben werden~\autocite{CNN}.

Wird in einer solchen Schicht jeder Filter auf jeder Position einzeln trainiert, so entstehen enorm viele trainierbare Parameter. Dies zeigt ein Beispiel eines Bildes der Grösse 227x227 Pixel und 96 Filter der Grösse 11x11 bei einem Stride von vier und Zero-Padding von null. Jeder Filter kann auf $1+(227-11)/4 = 55$ horizontal und 55 vertikal unterschiedlichen Positionen auf dem Bild angewendet werden. In diesem Fall entsteht ein Ausgabe-Vektor der Grösse 55x55x96. Die $55*55*96 = 290\textnormal{'}400$ Neuronen dieses Ausgabe-Vektors werden nun jeweils durch $11*11*3 = 363$ Gewichte und einen Bias berechnet. Dadurch entstehen $290'400*364 = 105\textnormal{'}705\textnormal{'}600$ trainierbare Parameter. Dieses Beispiel zeigt, dass dadurch bereits bei kleinen Bildern trotz hohem Stride eine grosse Anzahl an trainierbaren Parametern entsteht~\autocite{CNN}.

Durch sogenanntes Parameter Sharing kann die Anzahl der trainierbaren Parameter stark reduziert werden. Das Parameter Sharing basiert auf der Annahme, dass wenn ein Filter an einer räumlichen Position (x,y) angewendet werden kann, um ein visuelles Merkmal zu erkennen, dies auch für eine andere Position (x2,y2) gilt. Durch diese Annahme können die Parameter im oben genannten Beispiel auf $11*11*3 = 363$ Gewichte und einen Bias pro Filter reduziert werden. Dadurch wird die gesamte Anzahl an trainierbaren Parametern in diesem Beispiel auf $96*(363+1) = 34\textnormal{'}944$ reduziert. Durch diese Annahme eignen sich Convolution Neural Networks besonders gut für Problemstellungen mit Bildern~\autocite{CNN}. 

\textbf{Pooling Layer}

\nopagebreak

Nach einem oder teilweise mehreren Convolution Layern ist es üblich, einen Pooling Layer anzubringen. Dieser Pooling Layer reduziert die räumliche Dimension des Eingabe-Vektors. Eine der häufigsten Anwendungen ist ein Max Pooling Layer der Grösse 2x2 mit einem Stride von zwei. Dieser Max Pooling Layer reduziert jeden betrachteten 2x2 Ausschnitt aus dem Eingabe-Vektor auf das grösste Neuron. Dadurch halbiert er den Eingabe-Vektor horizontal sowie vertikal und reduziert somit die Anzahl Neuronen um 75\%. Anstelle von Max Pooling Layern kommen auch andere Verfahren wie der Average Pooling Layer zur Anwendung. Der Max Pooling Layer liefert meist bessere Resultate als ein Average Pooling Layer~\autocite{CNN}.

Pooling Layer kommen zur Anwendung, damit die Anzahl der trainierbaren Parametern und somit der Rechenaufwand tief gehalten werden kann. Pooling Layer helfen auch Overfitting zu vermeiden~\autocite{CNN}.

\subsection{Long-Short-Term-Memory Netzwerke}

Menschen starten ihren Denkprozess nicht jede Sekunde von Neuem. Beim Lesen wird jedes Wort aufgrund des Verständnisses des vorherigen Wortes verstanden. Gedanken sind persistent. Genau solche persistenten Gedanken sind mit den bisherigen Ansätzen für neuronale Netze nicht modellierbar. Hier kommen Recurrent Neural Networks (kurz RNN) ins Spiel. Recurrent Neural Networks sind neuronale Netzwerke mit integrierten Schlaufen~\autocite{Olah2015}. 

In Abbildung \ref{rnn1} wird ein RNN mit einer Schlaufe dargestellt. Daneben ist dasselbe Netzwerk in einer anderen, ausgerollten Weise zu sehen. Die Abbildung verdeutlicht, wie Informationen von einem Neuron zum anderen fliessen können. Mit diesem Informationsfluss von Neuron zu Neuron werden die Resultate jeweils von den vorhergehenden Neuronen beeinflusst. Damit wird eine Art Kurzzeitgedächtnis geschaffen, welches dem neuronalen Netzwerk erlaubt mit Kontextinformationen zu arbeiten~\autocite{Olah2015}.
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Informationsfluss durch ein Recurrent Neural Network}
    \label{rnn1}
    \centering
    \vspace{0.2cm}
    \includegraphics[width=0.6\textwidth]{graphics/rnn1.png}\\
    \vspace{0.3cm}
    \caption*{Quelle: \textcite{Olah2015}}
\end{figure}

Ein Problem von Recurrent Neural Networks ist, dass nur ein Kurzzeitgedächtnis zur Verfügung steht. Liegen Informationen länger zurück, sprich der Abstand zwischen den beiden relevanten Neuronen ist zu gross, gehen diese Informationen verloren. Eine Lösung für diese Problematik bieten Long-Short-Term-Memory (kurz LSTM) Netzwerke. Diese Spezialform von Recurrent Neural Networks arbeitet mit sogenannten Gates, um zu regulieren, wie viel Kontextinformationen behalten oder vergessen werden sollen. Mit vier solchen Gates, bestehend aus einem Neural Network Layer und einer Pointwise Operation (vgl. Abbildung \ref{lstm1}), ist ein LSTM Netzwerk in der Lage, nicht nur ein Kurz- sondern auch ein Langzeitgedächtnis aufzubauen~\autocite{Olah2015}.
\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Informationsfluss eines LSTM Netzwerk}
    \label{lstm1}
    \centering
    \includegraphics[width=0.6\textwidth]{graphics/lstm.png}\\
    \vspace{0.5cm}
    \includegraphics[width=0.6\textwidth]{graphics/lstm-notation.png}\\
    \vspace{0.2cm}
    \caption*{Quelle: \textcite{Olah2015}}
\end{figure}

Recurrent Neural Networks wurden in der Vergangenheit sehr erfolgreich für viele Aufgaben, wie beispielsweise die Spracherkennung, Sprachmodellierung, maschinelle Übersetzung sowie Objektkennung, angewendet. In den meisten Fällen wurden dabei LSTM Netzwerke angewendet, da die Resultate um ein Vielfaches besser ausfallen als mit herkömmlichen RNNs~\autocite{Olah2015}.

LSTM Netzwerke sind für diese Arbeit besonders zur Texterkennung und Rechtschreibkorrektur interessant. Diese beiden Techniken werden im Prototypen der Rechnungsindexierung verwendet.

\subsection{Texterkennung}

Ein wichtiger Bestandteil des Prototypen zur Indexierung von Rechnungen ist die Erkennung von Texten, in Druckbuchstaben oder Handschrift, auf Rechnungen. Die erkannten Texte bilden die Grundlage für jegliche digitale Verarbeitung der Rechnungen.

Die herkömmliche Feature-detection in Texterkennungssoftware wird immer mehr mit künstlicher Intelligenz ersetzt. \textcite{Neuberg2017} beschreibt wie Dropbox künstliche Intelligenz anwendet, um Texte aus Fotografien von Dokumenten durchsuchbar zu machen. Zur Anwendung kommen dabei verschiedene Techniken aus dem Bereich der künstlichen Intelligenz: \textit{Convolutional Neural Network}\footnote{Ein Convolutional Neural Network ist eine Spezialform eines neuronalen Netzwerks bei welchen, etwas vereinfacht ausgedrückt, viele Kopien des gleichen Neurons zum Einsatz kommen\autocite{Olah2014}.} (CNN), Long-Short-Term-Memory (LSTM) Netzwerke, Connectionist Temporal Classification\footnote{Connectionist Temporal Classification ist ein Konzept aus dem Training von neuronalen Netzwerken, welches vor allem in der Handschrifterkennung Verwendung findet. Dabei wird eine spezielle Trainingsfunktion verwendet, durch welche die Positionierung von Buchstaben generalisiert und somit der Lernprozess des neuronalen Netzwerks vereinfacht werden kann~\autocite{Scheidl2018}.} (CTC) und weitere~\autocite{Neuberg2017}.

Auch die Texterkennungssoftware Tesseract, welche ursprünglich als Forschungsprojekt im HP Lab entwickelt wurde und seit 2005 als Open Source Software zur freien Verfügung steht, verwendet seit Version 4 künstliche Intelligenz~\autocite{Smith2007}. So wurde die Feature-detecion durch ein LSTM Netzwerk mit mehr als 100 Schichten ersetzt. Die Texterkennung konnte so nicht nur qualitativ stark verbessert werden, sondern ist auch schneller als zuvor. Doch auch nach den Verbesserungen müssen die Ergebnisse fallspezifisch optimiert werden~\autocite{O.V.2018, O.V.2018a}.

\subsection{Word embedding}
\label{chap:embedding}

Neuronale Netzwerke funktionieren mit Zahlen. Damit auch Wörter und ganze Sätze von solchen Netzwerken verarbeitet werden können, muss eine geeignete Repräsentation von Wörtern durch Zahlen gefunden werden. Der Prozess, mit welchem ein Wort in eine zahlen-basierte Repräsentation gebracht wird, nennt sich Word embedding~\autocite{Olah2014b}.

Die ersten Word embeddings wurden von \textcite{Bengio2001} eingeführt. Trotz des schon fortgeschrittenen Alters dieses Forschungsgebietes ist es noch immer von neuen Entwicklungen geprägt~\autocite{Olah2014b}.

\begin{wrapfigure}{r}{0.5\textwidth} 
    \captionsetup{width=.9\linewidth}
    \caption[Modulares Netzwerk zur Validierung von 5-Grammen]{Modulares Netzwerk zur Validierung von 5-Grammen mit einer Word embedding Funktion ($W$) und einem neuronalen Netzwerk ($R$)}
    \label{wordembeddingtraining}
    \centering
    \includegraphics[width=0.48\textwidth]{graphics/wordembeddingtraining.png}
    \caption*{Quelle: \textcite{Olah2014b}}
\end{wrapfigure}
Technisch gesehen ist ein Word embedding eine parametrierte Funktion, welche Wörter einer bestimmten Sprache in einen hoch-dimensionalen Vektor (typischerweise 200-500 Dimensionen) transformiert. Um diese hoch komplexe Funktion zu definieren, kommt Machine Learning zum Einsatz. \textcite{Olah2014b} beschreibt in seinem Artikel ein Beispiel, bei welchem eine solche Word embedding Funktion trainiert wird. Die Resultate aus dem Word embedding werden in ein neuronales Netzwerk zur Prüfung eines 5-Grammes gespiesen und dann das Gesamtkonstrukt trainiert (vgl. Abbildung \ref{wordembeddingtraining})~\autocite{Olah2014b}.

Um sich Word embeddings besser vorstellen zu können, zieht \textcite{Olah2014b} zwei verschiedene Möglichkeiten der Visualisierung heran.

Die erste Visualisierung bedient sich dem t-SNE\footnote{t-Distributed Stochastic Neighbor Embedding (kurz t-SNE) ist eine Technik zur Reduktion von Dimensionen, welche besonders gut für Visualisierungen von hoch-dimensionalen Daten geeignet ist~\autocite{tSNE}.} Algorithmus um die hoch-dimensionalen Vektoren in einem zweidimensionalen Diagramm darzustellen. In einem solchen Diagramm ist klar zu erkennen, dass ähnliche Wörter nahe zusammen sind (vgl. Abbildung \ref{wordembeddingtsne})~\autocite{Olah2014b}.
\begin{figure}[h!]
    \centering
    \captionsetup{width=.9\linewidth}
    \caption{t-SNE Darstellung eines Word embeddings}
    \includegraphics[width=\textwidth]{graphics/wordmebeddingtsne.jpg}
    \caption*{Quelle: \textcite{Turian2010} in \textcite{Olah2014b}}
    \vspace*{0.3cm}
    \label{wordembeddingtsne}
\end{figure}

Die zweite Visualisierung listet in einer Tabelle (vgl. Tabelle \ref{wordembeddingtable}) für sechs Wörter die nächsten Embeddings, sprich mit den mathematisch nächsten Vektoren, auf. So werden beispielsweise unter dem Titel \textit{FRANCE} neben \textit{EUROPA} diverse weitere Länder aufgelistet.
\begin{table}[h!]
\centering
    \captionsetup{width=.9\linewidth}
    \caption{Sechs Ausgangswörter mit den ihnen ähnlichsten Word embeddings}
    \label{wordembeddingtable}
    \renewcommand{\arraystretch}{1.25}
    \setlength{\tabcolsep}{3pt}
    \footnotesize
    % \arrayrulecolor{black}
    \begin{tabular}{ | l | l | l | l | l | l |}
    \hline
    \rowcolor[HTML]{C0E5FD} FRANCE & JESUS & XBOX & REDDISH & SCRATCHED & MEGABITS \\ \hline
    AUSTRIA & GOD & AMIGA & GREENISH & NAILED & OCTETS \\ \hline
    BELGIUM & SATI & PLAYSTATION & BLUISH & SMASHED & MB/S \\ \hline
    GERMNAY& CHRIST & MSX & PINKISH & PUNCHED & BIT/S \\ \hline
    ITALY & SATAN & IPOD & PRUPLISH & POPPED & BAUD \\ \hline
    GREECE & KALI & SEGA & BROWNISH & CRIMPED & CARATS \\ \hline
    SWEDEN & INDRA & PS\textit{NUMBER} & GREYISH & SCRAPED & KBIT/S \\ \hline
    NORWAY & VISHNU & HD & GRAYISH & SCREWED & MEGAHERTZ \\ \hline
    EUROPE & ANANDA & DRAMCAST & WHITISH & SECTIONED & MEGAPIXELS \\ \hline
    HUNGARY & PARVATI & GEFORCE & SILVERY & SLASHED & GBIT/S \\ \hline
    SWITZERLAND & GRACE & CAPCOM & YELLOWISH & RIPPED & AMPERES \\ \hline
    \end{tabular}
    % \vspace{8pt}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{Collobert2011} in \textcite{Olah2014b}}
\end{table}

Sowohl Abbildung \ref{wordembeddingtsne} als auch Tabelle \ref{wordembeddingtable}, zeigen die Stärke von Word embeddings auf. Ähnliche Wörter werden mit ähnlichen Vektoren versehen und so wird eine komplexe Landschaft von zusammengehörigen Wörtern gebildet. Da somit zwei Synonyme ein ähnliches Word embedding aufweisen, verändert sich der Input-Vektor eines nachfolgenden neuronalen Netzwerks durch den Austausch dieser nur geringfügig. Somit muss dieses nachfolgende neuronale Netzwerk nicht für alle Wörter der Welt trainiert werden, sondern kann auf die Generalisierung durch das Word embedding aufbauen~\autocite{Olah2014b}.

Word embeddings sind zu einem extrem wichtigen Baustein bei der Verarbeitung von natürlichen Texten geworden. Neben Input und Output Repräsentationen bei NLP Tasks können Word embeddings auch Output Repräsentationen in der Objektkennung sein~\autocite{Olah2014b}. 

Für den Prototypen bilden Word embeddings eine wichtige Grundlage. Durch diese Technik können die in den Rechnungen enthaltenen Wörter und Sätze in eine generalisierte, durch neuronale Netzwerke verarbeitbare Form gebracht werden.

\subsection{Korrektur von Rechtschreibung und Grammatik}
\label{chap:grammar-correction}

Trotz grossem Fortschritt, nicht zuletzt dank der Verwendung von künstlicher Intelligenz, im Bereich der Texterkennung, werden Texte nicht zu 100\% korrekt erkannt. So schleichen sich falsch erkannte Buchstaben ein, welche nicht nur Wörter, sondern auch ganze Sätze bedeutungslos machen. Um solche Fehler zu korrigieren, wird auf die Rechtschreibung- und Grammatik-Korrektur zurückgegriffen. Während diverse Korrekturprogramme regelbasierte Software anwenden, wurde auch in diesem Bereich bereits erfolgreich künstliche Intelligenz angewandt. Mit Hilfe des Word embeddings und von LSTM Netzwerken können künstliche Intelligenzen zur Korrektur von Rechtschreibung und Grammatik geschaffen werden. So beschreibt \textcite{Weiss2016}, wie mit einem einfachen neuronalen Netzwerk, bestehend aus nur 4 LSTM und 4 Dropout Schichten, bereits erfolgreich Rechtschreibfehler korrigiert werden können. 

% can't use wrapfigure here as otherwise the next sections wraps too
\begin{figure}[h!] % wrapfigure}{l}{0.5\textwidth}
    \centering
    \captionsetup{width=.9\linewidth}
    \caption{Vergleich der Erfolgsrate bei der Prüfung von 418 Textsnippets}
    \label{deepgrammar}
    \includegraphics[scale=0.9]{graphics/matplot/grammar-tools.pdf}
    \caption*{Quelle: \textcite{Mugan}}
\end{figure} %wrapfigure}
Nicht nur zur Korrektur von Rechtschreibfehlern ist ein neuronales Netzwerk anwendbar, sondern auch zur Grammatikprüfung. So kann unter deepgrammar.com ein Experiment gefunden werden, bei welchem ein neuronales Netzwerk zur Grammatikprüfung angewendet wird. Die Resultate, welche in der Abbildung \ref{deepgrammar} zu sehen sind, sind erstaunlich. Obwohl DeepGrammar erst seit einem Jahr existiert und dabei von nur einer Person entwickelt wurde, funktioniert das Netzwerk beinahe so gut wie \textit{Microsoft Word}\footnote{Microsoft Word ist ein Programm zur Textverarbeitung und Dokumenterstellung von Microsoft~\autocite{MicrosoftCorporation2018}.} oder \textit{Language Tool 3.1}\footnote{\enquote{LanguageTool ist eine Software zur Textprüfung [...]}~\autocite{LanguageTool2018}.} und sogar besser als \textit{Grammarly}\footnote{Grammarly verspricht präzise, kontextabhängige Korrekturen von Texten~\autocite{GrammarlyInc.2018}.} und \textit{Google Docs}\footnote{Google Docs ist eine Online-Lösung zur Textverarbeitung von Google~\autocite{GoogleLLC2018}.}~\autocite{Mugan}.

% TODO: Mugan erwähnt eine bessere Studie. In der Thesis diese verwenden, da Zahlen aus DeepGrammar nicht 100% korrekt sind https://arxiv.org/pdf/1807.01270.pdf

Ein weiterer grosser Vorteil von neuronalen Netzwerken zur Fehlerkorrektur erwähnt \textcite{Mugan2018} in einer persönlichen Kommunikation mit dem Autoren dieser Arbeit. Das neuronale Netzwerk kann auf das Domänenspezifische Lexikon trainiert werden. Das Netzwerk kann beispielsweise mit medizinischen Begriffen aus den Rechnungen trainiert werden, so dass die Resultate des in dieser Arbeit entwickelten Prototypen noch besser werden~\autocite{Mugan2018}.

\subsection{Natural Language Processing}

Natural Language Processing (kurz NLP) beschreibt das Gebiet der Forschung und Anwendung von Computern um natürliche Sprache, in Wort und Schrift, zu verstehen und verarbeiten. NLP umfasst Forschungsfelder wie beispielsweise die maschinelle Übersetzung, die Spracherkennung sowie die Informationsextraktion~\autocite{Chowdhury2003}. 

Für diese Arbeit ist das Themengebiet des Natural Language Processing insofern relevant, als dass es die Grundlage für die Verarbeitung von Rechnungen bildet. Mit Techniken aus diesem Gebiet werden die Inhalte der Rechnungen vom Computer verstanden und verarbeitet.

\subsection{Informationsextraktion aus natürlichen Texten}
\label{chap:ner}

% https://en.wikipedia.org/wiki/Named-entity_recognition
% https://en.wikipedia.org/wiki/Medical_classification

Informationsextraktion beschreibt das Themengebiet rund um die Extraktion von strukturierten Informationen aus unstrukturiertem oder halb-strukturiertem Text. In diesem Kapitel werden einige Techniken aus diesem Themengebiet erläutert und deren Ein\-satz\-mög\-lich\-keit für die Entwicklung des Prototypen diskutiert.

Eine \textit{Regular Expression} (kurz RegEx) ist ein Ausdruck, welcher eine Zeichenkette beschreibt. Diese Ausdrücke funktionieren ähnlich wie arithmetische Ausdrücke. Es werden Operatoren verwendet, um mehrere Ausdrücke zu einem komplexeren Ausdruck zusammenzufassen~\autocite{Xiao2004}.

\textcite{Xiao2004} beschreibt als einfaches Beispiel den Ausdruck \texttt{[a,p]m [0-9]+:[0-9]+} um Zeitangaben wie AM 12:45 zu extrahieren. Dieses Beispiel zeigt einerseits die Einfachheit dieser Technik aber auch die Grenzen. 12:45 AM wird beispielsweise nicht erkannt, da AM hier nach anstelle vor der Uhrzeit steht. 

Ein weiterer Nachteil von Regular Expressions ist, dass Kontextinformationen nicht be\-rück\-sich\-tigt werden. Folgendes Beispiel von \textcite{Xiao2004} zeigt dies auf. Der Ausdruck \texttt{[0-9]+} ist zwar in der Lage aus dem Text \texttt{100\$} die Zahl \texttt{100} zu extrahieren, allerdings geht die Information, dass es sich hier um einen Geldbetrag handelt, verloren.

Um eine hohe Präzision bei der Informationsextraktion zu ermöglichen, sollten Regular Expressions also nur mit Vorsicht und in Kombination mit anderen Techniken verwendet werden~\autocite{Xiao2004}.

Named Entity Recognition and Classification (kurz NERC oder NER), beschreibt das erkennen und kategorisieren von Entitäten, sprich Wörter oder Wortgruppen aus natürlichen Texten~\autocite{Nadeau2007}.

Der Begriff Named Entity wurde bei der Formulierung der Aufgabenstellung der sechsten Message Understanding Conference im Jahre 1995 definiert~\autocite{Borthwick1998}. So wurde bereits damals erkannt, dass die Extraktion von Namen von Personen, Organisationen oder Lokationen, nummerischen Ausdrücken, Daten und Prozent-Ausdrücken wichtig ist~\autocite{Nadeau2007}.

Für die Named Entity Recognition and Classification stehen einige freie Softwarelösungen zur Verfügung. So veröffentlicht beispielsweise Stanford eine Java Implementierung und SpaCy, eine Sammlung von Natural Language Processing Software, beinhaltet eine Implementierung in Python~\autocite{StanfordNLPGroup, ExplosionAI}.

Die Anwendung von NERC ist für das Fallbeispiel interessant. Die Erkennung von Namen von Personen ist hilfreich zur Erkennung des Patienten und des Leistungserbringers. Weiter hilft die Erkennung von Daten der Ermittlung des Behandlungsdatums und nicht zuletzt kann durch die Erkennung und Klassifizierung von nummerischen Ausdrücken der Gesamtbetrag sowie die Beträge einzelner Positionen ermittelt werden.

Die letzte Technik, welche in diesem Kapitel erläutert wird, ist das Part of Speech Tagging (kurz PoS-Tagging). Beim PoS-Tagging werden Wörter und Satzzeichen ihren Wortarten (Nomen, Adjektive, etc.) zugewiesen~\autocite{Xiao2004}.

Die grösste Herausforderung beim PoS-Tagging sind Wörter welche verschiedenen Wortgruppen zugewiesen werden könnten. Beispielsweise kann das Wort \enquote{widerwillig} im Satz \enquote{Sie nannten den Täter widerwillig.} als Adjektiv oder Adverb aufgefasst werden und somit die Bedeutung des Satzes vollkommen verändern~\autocite{Volk}.

% Es gibt diverse Arten von Implementierung des PoS-Tagging, welche in regelbasierte, stochastische und neuronale Verfahren unterteilt werden können. Ein weit verbreiteter Ansatz ist die Verwendung von Hidden Markov Modellen. Ein Hidden Markov Modell ist ein stochastisches Modell, welches Zustände mit übergangswahrscheinlichkeiten modelliert.

% Die Verwendung von PoS-Tagging kann bei Rechnungen mit einem Prosatext von Vorteil sein. Wie viele relevante Informationen in Prosatexten von Rechnungen verborgen sind, muss sich aber erst noch zeigen.

% Die beschriebenen Techniken bieten eine gute Grundlage um damit eine erste Implementierung eines Prototypen zur Rechnungsindexierung zu beginnen.

% newpage here to keep graphics in the following sections in place
\newpage
\subsection{Klassifizierung von Bildern}
\label{chap:image-classification}

Die Klassifizierung von Bildern ist eine viel behandelte Problemstellung im Bereich der Computer Vision. Dabei geht es darum, ein Bild einer bestimmten Klasse zuzuweisen. Ist auf dem Bild beispielsweise ein Hund zu sehen, so ist es der Klasse Hund zuzuweisen~\autocite{Goodfellow2016}.

2012 gewann das AlexNet, eines der ersten Convolutional Neural Network basierten Modelle zur Klassifizierung von Bildern, mit einem grossen Abstand die ImageNet Large-Scale Visual Recognition Challenge\footnote{Die ImageNet Large Scale Visiual Recognition Competition (kurz ILSVRC) ist ein Wettbewerb der ImageNet Organisation, bei welcher hunderte Data Scientists ihre Modelle im Bereich der Computer Vision vergleichen.} (kurz ILSVRC). Seither sind tiefe neuronale Netzwerke die verbreitetste Methode zur Klassifizierung von Bildern. Diese tiefen neuronalen Netzwerke erreichen heute bessere Resultate als Menschen~\autocite{SSD}.

Auf dem Machine Learning Blog Towards Data Science beschreiben und vergleichen diverse Autoren verschiedenste Modelle im Bereich der Computer Vision. Der Blog bietet einen guten Überblick über die aktuellen Methoden zur Klassifizierung von Bildern. So werden im Juli 2017 die Residual Networks (kurz ResNet), entwickelt von \textcite{He2015}, als die bahnbrechendste Eingabe beim ImageNet LSVRC Wettbewerb der letzten Jahre bezeichnet~\autocite{Fungg2017ResNet}. Im September 2018 beschreibt \textcite{SHTsuang2018Inception} das InceptionV4 Netzwerk von Google, welches vom GoogLeNet abgeleitet und mit den Ideen aus dem ResNet erweitert wurde. Dieses Modell erzielt noch bessere Resultate als das ResNet selbst. Im gleichen Artikel wird auch das Inception-ResNet-V2 vorgestellt, welches im Vergleich zum InceptionV4 Netzwerk schneller trainiert werden kann und zugleich etwas bessere Resultate erzielt. 

In einem Blog Post auf dem Google AI Blog präsentieren Forscher aus dem Google Brain Team das NASNet. NASNet ist ein Modell zur Klassifizierung von Bildern, welches durch die Anwendung von Machine Learning designed wurde~\autocite{GoogleNasNet}. Unter dem Codename AutoML publiziert das Google Brain Team einen Ansatz, bei welchem ein neuronales Netzwerk ein anderes erstellt - eine künstliche Intelligenz, welche eine neue künstliche Intelligenz schafft. Mit diesem Ansatz kann der sehr aufwendige Design-Prozess zur Schaffung eines neuronalen Netzwerks vereinfacht beziehungsweise automatisiert werden~\autocite{GoogleAutoML}.

Als Teil des gleichen Blog Posts, in welchem das NASNet präsentiert wird, vergleichen die Forscher von Google das Modell mit anderen Netzwerken, wie dem ResNet und dem Inception-ResNet-V2. Der Abbildung \ref{nasnet-comparision} ist zu entnehmen, dass das vom Google Brain Team präsentierte NASNet, in der medium Ausprägung, trotz reduzierter Anzahl an benötigten Operationen, sprich reduzierter Komplexität, eine verbesserte Trefferquote als die bisherigen Netzwerke erzielt. In der large Ausprägung kann das NASNet durch eine erhöhte Komplexität eine noch bessere Trefferquote erzielen~\autocite{GoogleNasNet}.

\begin{figure}[h]
% \begin{wrapfigure}{r}{0.6\textwidth} 
    \captionsetup{width=.9\linewidth}
    \caption{Vergleich des NASNet mit anderen Netzwerken zur Klassifizierung von Bildern}
    \label{nasnet-comparision}
    \centering
    \includegraphics[width=0.55\textwidth]{graphics/nasnet-comparision.jpg}
    \vspace*{0.2cm}
    \caption*{Quelle: \textcite{GoogleNasNet}}
\end{figure}
%\end{wrapfigure}

\subsection{Objekterkennung in Bildern}
\label{chap:object-detection}

Bei der Objekterkennung in Bildern geht es darum, ein Bild nicht nur einer Klasse zuzuweisen, sondern zu erkennen, wo Objekte auf dem Bild sind. Die einzelnen Objekte werden dann einer Klasse zugewiesen. So könnte ein Bild beispielsweise Personen, Hunde, Pferde und Autos enthalten. Das Modell hat die Aufgabe, alle Objekte dieser Klassen zu umrahmen und zu erkennen, um welche Klasse es sich handelt~\autocite{Goodfellow2016}.

Das R-CNN Modell ist eines der ersten Modelle, welche die Convolutional Neural Network Architektur nutzt, um nicht nur Bilder zu klassifizieren, sondern auch die Position von Objekten zu erkennen. Die Ausgabe des R-CNN Modells sind mehrere Rechtecke als Umrandungen von Objekten und eine zugehörige Klasse (vgl. Abbildung \ref{fig:rcnn})~\autocite{SSD}.

\begin{figure}[h]
% \begin{wrapfigure}{r}{0.6\textwidth} 
    \captionsetup{width=.9\linewidth}
    \caption{Resultate aus einem Modell zur Objekterkennung in Bildern}
    \label{fig:rcnn}
    \centering
    \includegraphics[scale=0.4]{graphics/rcnn.png}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{SSD}}
\end{figure}
%\end{wrapfigure}

Die Fast R-CNN und Faster R-CNN Modelle bieten Verbesserung in Hinblick auf die Geschwindigkeit und die Genauigkeit. Das Faster R-CNN Modell ist bis heute eines der exaktesten Modelle zur Objekterkennung in Bildern~\autocite{SSD}.

Trotz der verbesserten Geschwindigkeit des Faster R-CNN Modells ist mit den auf dem R-CNN Modell basierenden Modellen keine Objekterkennung in Echtzeit möglich. Die Modelle sind hierfür nicht performant genug. Das Single-Shot Multibox Detector (kurz SSD) und das You Only Look Once Modell bieten mit anderen Architekturen eine bessere Performance. Single-Shot bedeutet, dass die Modelle mehrere Objekte in nur einem Feed-Forward Durchgang erkennen können. Durch diese Änderung in der Architektur und dadurch verbesserte Geschwindigkeit, wird an Genauigkeit eingebüsst~\autocite{SSD}.

\subsection{Transfer Learning}
\label{chap:transfer-learning}

Transfer Learning beschreibt das Vorgehen, bei welchem das Gelernte aus einer Aufgabe genutzt wird, um das Lernen für eine andere Aufgabe zu vereinfachen~\autocite{Goodfellow2016}.

Beim Transfer Learning wird ein Modell verwendet, um zwei oder mehr verschiedene Aufgaben zu lösen. Es wird dabei angenommen, dass die Vorhersagen für eine Aufgabe aufgrund ähnlicher Kriterien getroffen werden, wie für jene einer anderen Aufgabe. Dies ist typischerweise dann der Fall, wenn die Eingabewerte eines Modells gleich oder ähnlich sind, sich die Art der gesuchten Ausgabewerte aber unterscheidet~\autocite{Goodfellow2016}.

Ein Modell wird trainiert, Bilder von Hunden und Katzen zu klassifizieren. Dabei stehen viele Trainingsdaten zur Verfügung. Nun soll ein Modell entwickelt werden, welches Bilder von Ameisen und Wespen klassifiziert. Sind nun für die zweite Aufgabe nur wenige Trainingsdaten verfügbar, so ist es ratsam, das Modell aus der ersten Aufgabe als Grundlage zur Lösung der zweiten Aufgabe zu verwenden. Viele visuelle Repräsentationen teilen grundlegende Eigenschaften wie Formen und Kanten, so kann die Wiederverwendung des trainierten Modells aus der ersten Aufgabe die Trefferquote in der zweiten Aufgabe stark erhöhen~\autocite{Goodfellow2016}.

Wird ein Modell, welches bereits für eine Aufgabe trainiert wurde, für eine zweite Aufgabe weiter trainiert, spricht man von Fine-tuning~\autocite{Goodfellow2016}.

Ursprünglich kommt das Transfer Learning aus dem Bereich der Computer Vision. Im Jahr 2018 präsentierten \textcite{Howard2018} sowie \textcite{Devlin2018} mit ULMFiT\footnote{Universal Language Model Fine-tuning, kurz ULMFiT, ist ein Ansatz, bei welchem ein Modell auf einem sehr grossen Datensatz trainiert wird. Dieses Modell kann nun für diverse Aufgaben im Gebiet des Natural Language Processing verwendet werden und verspricht bessere Ergebnisse als Ansätze ohne Transfer Learning~\autocite{Howard2018}.} respektive BERT\footnote{Bidirectional Encoder Representations from Transformes, kurz BERT, ist eine neuartige Repräsentation von natürlicher Sprache. Mit diesem auf Transfer Learning basierten Ansatz konnte das Google AI Language Team in diversen NLP Aufgaben Bestresultate erzielen~\autocite{Devlin2018}.} Ansätze, das Transfer Learning auch für Aufgaben im Gebiet des Natural Language Processing anzuwenden. Beide Ansätze versprechen die Reduktion der Menge benötigter Traingsdatensätze sowie die Verbesserung der resultierenden Modelle.

% newpage here to keep following pragraphs together, as it looks weird otherwise
\newpage
\subsection{Messkriterien zur Bewertung eines Systems mit künstlicher Intelligenz}
\label{chap:metrices}

Um ein System objektiv zu Bewerten und mit anderen Ansätzen zu vergleichen, bedarf es Metriken. Folgend werden die für diese Arbeit relevanten Metriken erläutert und ihre Anwendungsfälle diskutiert.

\subsubsection{Trefferquote}

Die Trefferquote, englisch Accuracy (kurz acc), ist die Metrik, welche wohl am meisten im Zusammenhang mit der künstlichen Intelligenz zu finden ist~\autocite{TDSAccuracy}.

Die Trefferquote gibt Auskunft darüber, wie viele der Vorhersagen eines Systems der Wirklichkeit entsprechen. Die Formell lautet wie folgt~\autocite{TDSAccuracy}: 

\nopagebreak
$$Accuracy = 1 - \frac{False Positive + False Negative}{Total Records}$$
\vspace*{0.2cm}

Die Confusion Matrix in Abbildung \ref{cm-sample} zeigt ein Beispiel mit einer Trefferquote von 0.99, respektive 99.9\%. Aus 1000 Datensätzen wurden 998 korrekt als Negativ klassifiziert. Ein Datensatz wurde korrekt als Positiv klassifiziert und ein Datensatz wurde fälschlicherweise als Negativ klassifiziert~\autocite{TDSAccuracy}.

\begin{figure}[h!]
    \centering
    \captionsetup{width=.9\linewidth}
    \caption{Beispiel einer Confusion Matrix}
    \label{cm-sample}
    \def\arraystretch{1.5}
    \arrayrulecolor{black}
    \begin{tabular}{llcc}
        \multicolumn{2}{l}{}                                                                       & \multicolumn{2}{c}{\textbf{Vorhersage / Klassifizierung}}   \\ \cline{3-4} 
        \multicolumn{1}{c}{\textbf{}}                               & \multicolumn{1}{l|}{}        & \multicolumn{1}{c|}{Negativ} & \multicolumn{1}{c|}{Positiv} \\ \cline{2-4} 
        \multicolumn{1}{l|}{\multirow{2}{*}{\textbf{Wirklichkeit}}} & \multicolumn{1}{l|}{Negativ} & \multicolumn{1}{c|}{998}    & \multicolumn{1}{c|}{0}       \\ \cline{2-4} 
        \multicolumn{1}{l|}{}                                       & \multicolumn{1}{l|}{Positiv} & \multicolumn{1}{c|}{1}       & \multicolumn{1}{c|}{1}       \\ \cline{2-4} 
    \end{tabular}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{TDSAccuracy}}
\end{figure}

Eine Trefferquote von 99.9\% ist sehr gut. Das Modell könnte durchaus als sehr erfolgreich betrachtet werden. Diese Betrachtung ist jedoch abhängig vom Anwendungsfall des Modells. Wenn das Modell die Infektion mit einem hoch ansteckenden Virus ermitteln würde, so wäre eine Infektion unentdeckt geblieben. In diesem Fall wäre eine geringere Trefferquote des Modells besser, wenn dafür keine falsche negativ Vorhersagen vorhanden wären~\autocite{TDSAccuracy}.

\subsubsection{Genauigkeit}

Die Genauigkeit, englisch Precision, sagt aus, wie viele als positiv vorhergesagten Datensätze wirklich Positiv sind. Die Formell dazu lautet~\autocite{TDSAccuracy}: 

\nopagebreak
$$Precision = \frac{True Positive}{True Positive + False Positive} = \frac{True Positive}{Total Predicted Positive}$$
\vspace*{0.2cm}

Die Abbildung \ref{cm-precision} veranschaulicht die Elemente zur Berechnung der Genauigkeit in einer Confusion Matrix.

\begin{figure}[h!]
    \centering
    \captionsetup{width=.9\linewidth}
    \caption{Elemente zur Berechnung der Genauigkeit in einer Confusion Matrix}
    \label{cm-precision}
    \def\arraystretch{1.5}
    \begin{tabular}{llcc}
        \multicolumn{2}{l}{}                                                                        & \multicolumn{2}{c}{\textbf{Vorhersage / Klassifizierung}}                                         \\ \cline{3-4} 
        \multicolumn{1}{c}{\textbf{}}                                & \multicolumn{1}{l|}{}        & \multicolumn{1}{c|}{Negativ}        & \multicolumn{1}{c|}{\cellcolor[HTML]{B5D0EE}Positiv}        \\ \cline{2-4} 
        \multicolumn{1}{l|}{}                                        & \multicolumn{1}{l|}{Negativ} & \multicolumn{1}{c|}{True Negative}  & \multicolumn{1}{c|}{\cellcolor[HTML]{B5D0EE}False Positive} \\ \cline{2-4} 
        \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{Wirklichkeit}}} & \multicolumn{1}{l|}{Positiv} & \multicolumn{1}{c|}{False Negative} & \multicolumn{1}{c|}{\cellcolor[HTML]{B5D0EE}True Positive}  \\ \cline{2-4} 
    \end{tabular}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{TDSAccuracy}}
\end{figure}

Die Genauigkeit bietet sich immer dann als gute Metrik an, wenn die Kosten eines False Positive hoch sind. Ein Beispiel dafür ist ein Spamfilter. Markiert der Spamfilter ein E-Mail fälschlicherweise als kein Spam, so ist dies kein Problem. Der Anwender kann das E-Mail manuell als Spam markieren. Markiert der Spamfilter jedoch ein E-Mail fälschlicherweise als Spam, so ist die Wahrscheinlichkeit hoch, dass der Anwender das E-Mail nie lesen wird~\autocite{TDSAccuracy}.

\subsubsection{Sensitivität}

Die Sensitivität, englisch Recall, sagt aus, wie viele wirklich positiven Datensätze als Positiv vorhergesagt werden. Die Formel zur Berechnung der Sensitivität lautet~\autocite{TDSAccuracy}: 

\nopagebreak

$$Precision = \frac{True Positive}{True Positive + False Negative} = \frac{True Positive}{Total Actual Positive}$$
\vspace*{0.2cm}

Die Abbildung \ref{cm-recall} veranschaulicht die Elemente zur Berechnung der Sensitivität in einer Confusion Matrix.

\begin{figure}[h!]
    \centering
    \captionsetup{width=.9\linewidth}
    \caption{Elemente zur Berechnung der Sensitivität in einer Confusion Matrix}
    \def\arraystretch{1.5}
    \begin{tabular}{llcc}
        \multicolumn{2}{l}{}                                                                                                & \multicolumn{2}{c}{\textbf{Vorhersage / Klassifizierung}}                                                                \\ \cline{3-4} 
        \multicolumn{1}{c}{\textbf{}}                                & \multicolumn{1}{l|}{}                                & \multicolumn{1}{c|}{Negativ}                                & \multicolumn{1}{c|}{Positiv}                               \\ \cline{2-4} 
        \multicolumn{1}{l|}{}                                        & \multicolumn{1}{l|}{Negativ}                         & \multicolumn{1}{c|}{True Negative}                          & \multicolumn{1}{c|}{False Positive}                        \\ \cline{2-4} 
        \multicolumn{1}{l|}{\multirow{-2}{*}{\textbf{Wirklichkeit}}} & \multicolumn{1}{l|}{\cellcolor[HTML]{B5D0EE}Positiv} & \multicolumn{1}{c|}{\cellcolor[HTML]{B5D0EE}False Negative} & \multicolumn{1}{c|}{\cellcolor[HTML]{B5D0EE}True Positive} \\ \cline{2-4} 
    \end{tabular}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{TDSAccuracy}}
    \label{cm-recall}
\end{figure}

Die Sensitivität ist immer dann relevant, wenn die Auswirkungen durch ein False Negative gross sind. Ein Beispiel dafür ist die Klassifizierung von Banktransaktionen auf Betrug. Wird eine nicht-Betrug Transaktion als Betrug markiert, so kann dies abgeklärt und korrigiert werden. Wird jedoch eine Betrug Transaktion nicht als solche erkannt, so sind die finanziellen Auswirkungen womöglich gross~\autocite{TDSAccuracy}.

\subsubsection{F-Mass}
\label{chap:f1-score}

Das F-Mass, englisch F\textsubscript{1}-Score, vereint die Genauigkeit und die Sensitivität. Im Gegensatz zur Trefferquote lässt sich der Wert aber nicht durch ein Übermass an True Negatives beeinflussen, denn sie finden keine Beachtung bei der Berechnung. In den meisten Anwendungsfällen sind True Negatives nicht relevant. False Negatives und False Positives sind meist die Verursacher von potentiell verursachten Kosten. Das F-Mass wird mit folgender Formel berechnet~\autocite{TDSAccuracy}:

\nopagebreak

$$F_1=2 * \frac{\textnormal{Genauigkeit} * \textnormal{Sensitivität}}{\textnormal{Genauigkeit} + \textnormal{Sensitivität}}$$
\vspace*{0.2cm}

Das F-Mass ist eine gute Verbindung der Genauigkeit und der Sensitivität. Aufgrund der Vernachlässigung der True Negatives ist das F-Mass besonders bei ungleichmässig verteilten Klassen, sprich übermässig vielen True Negatives, sinnvoll~\autocite{TDSAccuracy}.

\subsubsection{Loss und Loss-Funktion}

Das sogenannte Loss, auch Kosten oder Fehler, zeigt, wie sehr eine Vorhersage von der Realität abweicht. Um das Loss zu berechnen, kommt die Loss-Funktion, auch Kosten- oder Fehler-Funktion, zur Anwendung. Wie genau die Loss-Funktion definiert wird, hängt von der Problemstellung ab. Bei einer binären Klassifikation ist beispielsweise die Cross-Entropy-Loss–Function oder die Log-Loss–Function gängig~\autocite{TDSLoss}. 

Während dem Training ist das Loss, in diesem Fall die Differenz zwischen Vorhersage des Modells und den Trainingsdaten, die zu optimierende Grösse. Die Wahl der Loss-Funktion kann einen erheblichen Einfluss auf das Modell haben. Die Loss-Funktion wird während dem Training meist durch Regularisierungstechniken erweitert, um ein Overfitting zu verhindern~\autocite{Goodfellow2016}.

\subsubsection{Intersection over Union}

Um die Trefferquote, Genauigkeit und die Sensitivität zu berechnen, muss bekannt sein, ob eine Vorhersage eines Modells korrekt war oder nicht. Das bedeutet, es muss bekannt sein, ob es sich um einen True Positive, False Positive, True Negative oder False Negative handelt. 

Bei der Objekterkennung in Bildern ist dies nicht immer eindeutig zu sagen. Ein Modell zur Objekterkennung sagt eine Position eines Objektes, als umschliessendes Rechteck, sowie dessen Klasse vorher. Die Korrektheit der Klasse kann klar beurteilt werden. Entweder die Vorhersage stimmt mit der Erwartung überein oder nicht. Die Beurteilung der Korrektheit der vorhergesagten Position ist dagegen nicht eindeutig, wie dies Abbildung \ref{fig:iou-issue} verdeutlicht. Die Vorhersage des Modells trifft nicht exakt die Erwartung, doch deshalb ist die Vorhersage nicht falsch. Eine exakte Übereinstimmung des vorhergesagten und des erwarteten Rechtecks ist unwahrscheinlich. Aus diesem Grund ist eine Metrik notwendig, die solche Ungenauigkeiten zulässt~\autocite{IoU}.

\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Beispiel einer tatsächlichen und vorhergesagten Position eines Objekts}
    \label{fig:iou-issue}
    \centering
    \includegraphics[width=0.6\textwidth]{graphics/iou/iou_issue.jpg}\\
    \includegraphics[scale=1]{graphics/matplot/iou_issue_legend.pdf}
    \caption*{Quelle: \textcite{IoU}}
\end{figure}

Intersection over Union, kurz IoU, ist ein solches Mass. Es stellt, wie es der Name bereits sagt, die Überlappung des vorhergesagten mit dem erwarteten Rechteck in das Verhältnis zur Vereinigung dieser~\autocite{IoU}:

$$IoU = \frac{
    \textnormal{Fläche der Überlappung} \hspace{10pt} \includegraphics[width=20pt]{graphics/iou/intersection.pdf}
}{
    \textnormal{Fläche der Vereinigung} \hspace{12pt} \includegraphics[width=20pt, align=t]{graphics/iou/union.pdf}
}$$
\vspace*{0.2cm}

Die Beispiele aus Abbildung \ref{fig:iou-examples} verdeutlichen, dass das Mass gegen 1 tendiert, je exakter das vorhergesagte mit dem erwarteten Rechteck übereinstimmt. Es kann damit beurteilt werden, wie genau die Vorhersage ist. Wird nun noch ein Schwellenwert definiert, ab welchem eine Vorhersage als Korrekt angesehen wird, so kann die Korrektheit der Vorhersage ermittel werden. Die Wahl dieses Schwellenwerts ist sehr unterschiedlich. In Objekterkennungs-Wettbewerben sind Schwellenwerte zwischen 0.5 und 0.75 üblich. Auch wird teilweise ein Durchschnitt über mehrere Schwellenwerte verwendet~\autocite{IoU}.

\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Beispiele des Intersection over Union Mass}
    \label{fig:iou-examples}
    \centering
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \caption*{$IoU=0.4034$}
        % rescaling doesn't matter as there is no text in the graphics
        \includegraphics[width=0.5\linewidth]{graphics/iou/iou_examples/1.pdf}
        \caption*{Schlecht} 
        \vspace{2ex}
    \end{subfigure}%% 
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \caption*{$IoU=0.7330$} 
        % rescaling doesn't matter as there is no text in the graphics
        \includegraphics[width=0.5\linewidth]{graphics/iou/iou_examples/2.pdf}
        \caption*{Gut} 
        \vspace{2ex}
    \end{subfigure}%% 
    \begin{subfigure}[b]{0.3\linewidth}
        \centering
        \caption*{$IoU=0.9264$}
        % rescaling doesn't matter as there is no text in the graphics
        \includegraphics[width=0.5\linewidth]{graphics/iou/iou_examples/3.pdf}
        \caption*{Sehr gut} 
        \vspace{2ex}
    \end{subfigure}
    
    \caption*{Quelle: \textcite{IoU}}
\end{figure}

\subsubsection{Average Precision}
\label{chap:ap}

Average Precision, kurz AP, ist eine Metrik, welche oft bei der Bewertung von Modellen zur Objekterkennung zur Anwendung kommt. Als Average Precision wird der Durchschnitt aller Genauigkeiten bei jeder Sensitivität verstanden. Um dies genauer zur erläutern wird im Folgenden ein Beispiel zur Berechnung aufgeführt~\autocite{AP}.

Wird ein Modell zur Erkennung von fünf Katzen auf zehn Bildern angewendet, so sind insgesamt fünf True Positive Beispiele vorhanden. Die Tabelle \ref{tab:ap-example} zeigt mögliche Ergebnisse des Modells. Die Ergebnisse sind sortiert nach der Konfidenz des Modells, richtig zu liegen. Pro Vorhersage wird nun die Genauigkeit sowie die Sensitivität berechnet. Dabei steigt die Sensitivität bei jeder korrekten Vorhersage. Die Genauigkeit steigt bei jeder korrekten Vorhersage und sinkt bei jeder falschen~\autocite{AP}.

\begin{table}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Beispiel der Berechnung der Genauigkeit und Sensitivität}
    \label{tab:ap-example}
    \centering
    \begin{tabular}{|l|l|l|l|} 
    \hline
    Rang & Korrekte Vorhersage & Genauigkeit & Sensitivität  \\ 
    \hline
    1    & Ja                  & 1.0         & 0.2           \\ 
    \hline
    2    & Ja                  & 1.0         & 0.4           \\ 
    \hline
    3    & Nein                & 0.67        & 0.4           \\ 
    \hline
    4    & Nein                & 0.5         & 0.4           \\ 
    \hline
    5    & Nein                & 0.4         & 0.4           \\ 
    \hline
    6    & Ja                  & 0.5         & 0.6           \\ 
    \hline
    7    & Ja                  & 0.57        & 0.8           \\ 
    \hline
    8    & Nein                & 0.5         & 0.8           \\ 
    \hline
    9    & Nein                & 0.44        & 0.8           \\ 
    \hline
    10   & Ja                  & 0.5         & 1.0           \\
    \hline
    \end{tabular}
    \vspace*{0.3cm}
    \caption*{Quelle: \textcite{AP}}
\end{table}

Die Abbildung \ref{fig:ap-pr} zeigt die sogenannte Precision-Recall-Curve (kurz PR-Curve) für das Beispiel aus Tabelle \ref{tab:ap-example}. Die PR-Curve zeigt die Genauigkeit bei jeder Sensitivität. Die Sensitivität ist aufgrund ihrer Definition immer monoton steigend. Die Genauigkeit steigt beziehungsweise sinkt bei korrekten respektive falschen Vorhersagen. Auf der Abbildung ist die daraus resultierende Zickzacklinie zu sehen~\autocite{AP}.

\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Beispiel einer PR-Curve}
    \label{fig:ap-pr}
    \centering
    \includegraphics[scale=1]{graphics/matplot/ap__pr.pdf}\\
    \caption*{Quelle: \textcite{AP}}
\end{figure}

Wie erwähnt, wird als Average Precision der Durchschnitt aller Genauigkeiten bei jeder Sensitivität verstanden. Die Average Precision wird generell als die Fläche unter der PR-Curve definiert. Die Formel zur Berechnung der Average Precision lautet~\autocite{AP}:

\nopagebreak 
$$AP = \int_{0}^{1}p(r)dr$$
\vspace*{0.2cm}

Da sowohl die Genauigkeit als auch die Sensitivität zwischen 0 und 1 liegt, fällt auch die Average Precision zwischen 0 und 1~\autocite{AP}.

Um die Berechnung der Average Precision zu vereinfachen, wird die Zickzacklinie oftmals geglättet. Dafür wird zu jeder Sensitivität jeweils die maximale Genauigkeit aller grösseren Sensitivitäten gewählt~\autocite{AP}. Die grüne Linie in Abbildung \ref{fig:pr-smoothed} veranschaulicht diese Glättung.

\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Beispiel zur Glättung einer PR-Curve}
    \label{fig:pr-smoothed}
    \centering
    \includegraphics[scale=1]{graphics/matplot/ap__pr-smoothed.pdf}\\
    \caption*{Quelle: \textcite{AP}}
\end{figure}

Neben dieser Glättung kommt in gewissen Fällen auch eine Interpolation zur Anwendung. Bis 2008 verwendete das PASCAL VOC Dataset zur Berechnung der Average Precision eine Interpolation mit elf Punkten. Das bedeutet, dass die Genauigkeit bei allen Sensitivitäts-Werten mit dem Faktor 0.1 berechnet wird. Beim COCO\footnote{Das COCO (Common Objects in Context) Dataset ist ein sehr grosses Dataset, welches für diverse Wettbewerbe im Bereich der Objekterkennung verwendet wird.} Dataset wird eine Interpolation von 101 Punkten verwendet. Im neueren PASCAL VOC Dataset\footnote{Die PASCAL Visual Object Classes Datasets sind ein annotierte Datensätze zur Objekterkennung auf Bildern, welche von 2005 bis 2012 für die PASCAL VOC Challenge ausgegeben wurden.} wird auf eine Interpolation verzichtet und die Average Precision wird als die Fläche unter der geglätteten PR-Curve berechnet. In der Abbildung \ref{fig:pr-interpolated} ist ersichtlich, dass je nach Art der Berechnung unterschiedliche Werte resultieren. Durch die Interpolation können Ungenauigkeiten entstehen, wenn die Abnahme der Genauigkeit nicht genau auf einen der zur Berechnung verwendeten Punkte fällt. Beim Vergleich von Modellen muss darauf geachtet werden, dass die Modelle nicht aufgrund unterschiedlich berechneter Average Precisions beurteilt werden. Ansonsten kann ein falscher Eindruck entstehen~\autocite{AP}.

\begin{figure}[h!]
    \captionsetup{width=.9\linewidth}
    \caption{Interpolation einer geglätteten PR-Curve.}
    \label{fig:pr-interpolated}
    \centering
    \includegraphics[scale=1]{graphics/matplot/ap__pr-interpolated.pdf}\\
    \caption*{Quelle: \textcite{AP}}
\end{figure}

\subsubsection{Mean Average Precision}
\label{chap:map}

Als Mean Average Precision (kurz mAP) wird der Durchschnitt über mehrere Average Precisions bezeichnet. Welche Average Precisions dabei gemeint sind, ist von Anwendung zu Anwendung unterschiedlich. In gewissen Fällen wird einfach nur von der Average Precision gesprochen, obwohl eigentlich ein Durchschnitt über mehrere Average Precisions gemeint ist. Es wird davon ausgegangen, dass dies im Kontext klar ist. Im Folgenden werden drei Varianten zur Bildung der Mean Average Precision erläutert~\autocite{AP}.

Im COCO Dataset wird der Durchschnitt der Average Precisions für unterschiedliche Schwellenwerte für das Intersection over Union Verfahren als Mean Average Precision bezeichnet. Konkret werden alle Average Precisions für die IoU Schwellenwerte in Schritten von 0.05 zwischen 0.5 und 0.95 gemittelt. Dies wird dabei als $mAP[0.5:0.05:0.95]$ oder kürzer $mAP[0.5:0.95]$ bezeichnet. Durch dieses Verfahren werden Modelle mit genaueren Vorhersagen, sprich grösserem IoU Wert, besser bewertet~\autocite{AP}.

In anderen Fällen wird Mean Average Precision als der Durchschnitt der Average Precisions über alle zu identifizierenden Klassen berechnet. Sollen in einer Aufgabe Hunde und Katzen auf Bildern erkannt werden, so kann für beide Klassen eine Average Precision ermittelt werden. Ein Modell könnte eine Average Precision für Hunde von 0.9 und eine für Katzen von 0.3 aufweisen. Um dieses Modell nun mit einem anderen Modell zu vergleichen, wird die Mean Average Precision über alle Klassen berechnet. Dafür kommt folgende Formel zur Anwendung~\autocite{AP}:

\nopagebreak
$$mAP = \frac{\sum_{i=0}^{n}AP_{i}}{n} = \frac{AP_{Hund}+AP_{Katze}}{2} = 0.6$$
\vspace*{0.2cm}

Die beiden Methoden werden oft kombiniert, um die Mean Average Precision über mehrere Intersection over Union Schwellenwerte und über mehrere Klassen zu berechnen. Dies ermöglicht, verschiedene Modelle mit nur einer Zahl zu vergleichen~\autocite{AP}.

\subsection{Fehleranalyse}
\label{chap:error-analysis}

Als Fehleranalyse wird die Analyse der falschen Vorhersagen eines Modells bezeichnet. Im Falle eines Klassifizierungsmodells werden die falsch klassifizierten Datensätze betrachtet und auf die Ursache der falschen Klassifizierung untersucht. Das Ziel der Fehleranalyse ist es, Optimierungspotential zu finden, anhand welchem das bestehende Modell verbessert werden kann~\autocite{MLYearning}.

Wird beispielsweise ein Modell zur Klassifizierung von Bildern in die Klassen Hund und Katze mit einer Trefferquote von 90\% untersucht, so könnte eine Erkenntnis sein, dass nur 5\% aller falsch klassifizierten Bilder der Klasse Hund angehören. Durch Optimierungen des Modells zur besseren Erkennung von Hunden könnte nur 5\% des Fehlers reduziert, sprich 0.5\% an Trefferquote gewonnen werden. Würden 50\% der falsch Klassifizierten Bilder der Klasse Hund angehören, würde eine solche Optimierung einen grösseren Einfluss auf die Trefferquote haben. Die Reduktion der Fehler um 50\% würde eine Steigerung der Trefferquote von 5\% (50\% der Fehlerquote von 10\%) ermöglichen~\autocite{MLYearning}.

Die Fehleranalyse ermöglicht die Ursachen einer falschen Klassifizierung zu finden. Sie kann somit Auskunft darüber geben, wie das untersuchte Modell optimiert respektive weiterentwickelt werden soll~\autocite{MLYearning}.

%- Betrachtung der Falsch Klassifizierten Daten
%- Ziel: Optimierungspotential finden
%- Beispiel 5\% der falsch Klassifizierten Bilder sind Hunde. Egal wie startk für Hunde optimiert wird, es wird maximal 5\% des Fehlers optimiert
%- Fehleranalyse zeigt, in welche Richtung weiter vorgegangen werden soll
%- Fehleranalyse hilft die Ursachen der Falschklassifizierung zu finden
%- Kann helfen, unbekannte Gebiete durch ein iteratives vorgehen zu explorieren

\subsection{Design eines Systems mit künstlicher Intelligenz}

Die vorherigen Kapitel haben einen Einblick in einige der Grundbausteine von Machine Learning Modellen gegeben. Eine grosse Herausforderung ist nun, diese so anzuwenden, dass eine Problemstellung möglichst optimal gelöst werden kann. Dieses Kapitel soll einen Überblick darüber geben, wie ein Machine Learning Modell entwickelt werden kann, um eine Problemstellung anzugehen.

% - https://towardsdatascience.com/machine-learning-general-process-8f1b510bd8af
Der erste und einer der wichtigsten Schritte ist, die \textbf{Beschreibung der Problemstellung}. Dabei gilt es zu klären, was das Ziel ist respektive was vorhergesagt werden soll. Es muss geklärt werden, wie genau die Ausgabe des Modells aussehen soll. Weiter muss geklärt werden, welche Daten als Eingabewerte notwendig und ob diese verfügbar sind. Weiter gilt es zu definieren, anhand welcher Metrik das Modell gemessen wird~\autocite{DesignML}.

Der nächste Schritt ist die \textbf{Beschaffung der identifizierten Daten}. Für gewisse Problemstellungen sind bereits strukturierte Daten vorhanden. Bei anderen müssen diese mit aufwendigen Techniken wie Web-Scraping, dem automatisierten extrahieren von Informationen aus Webseiten, beschafft werden~\autocite{DesignML}.

Im dritten Schritt muss eine \textbf{Zielmetrik} bestimmt werden. Die Wahl der Metrik ist wichtig, damit das Ziel bekannt ist und das Modell auf die Erreichung dieses optimiert werden kann~\autocite{DesignML}.

Nachdem das Ziel definiert ist, müssen die \textbf{Eingabedaten aufbereitet} werden. Dabei muss ein Weg gefunden werden, mit potentiell fehlenden oder unvollständigen Daten umzugehen. Alle Daten müssen in eine Form gebracht werden, welche das Modell verstehen kann. So müssen beispielsweise ordinale und nominale Daten in Ganzzahlen umgewandelt respektive codiert werden. Da die meisten Modelle mit gleich skalierten Daten am besten umgehen können, werden die Daten auf die Skala $[0:1]$ gebracht~\autocite{DesignML}.

Je nach Problematik ist es Ratsam eine \textbf{einfache Vorhersage}, beispielsweise basierenden auf k-Nearest-Neighbor\footnote{k-Nearest-Neighbor ist ein Algorithmus zur Klassifizierung eines Datensatzes aufgrund seiner k-nächsten Nachbarn, sprich k-ähnlichsten Datensätzen.} oder Naïve Bayes\footnote{Naïve Bayes ist ein Algorithmus zur Klassifizierung, welcher Datensätze aufgrund einer Kostenfunktion klassifiziert. Ein Datensatz wird jener Klasse zugewiesen, bei welcher die kleinsten Kosten entstehen.}, zu erstellen. Eine solche Vorhersage ermöglicht die Eingabedaten auf ihre Eignung zur Vorhersage des gesuchten Resultats zu prüfen. Das Resultate dieser einfachen Vorhersage kann als Grundlage zur Bewertung des Machine Learning Modells verwendet werden~\autocite{DesignMLSecondaryCite}.

Nachdem alle Rahmenbedingungen geschaffen sind, geht es an die \textbf{Entwicklung des Modells}. Dabei ist die Cross Validation, der Vergleich von bestehenden Modellen, und das anschliessende Optimieren des besten Kandidaten, ein oft angewendetes Vorgehen. Bei der Cross Validation werden verschiedene Modelle auf den Eingabedaten angewendet und anhand der Zielmetrik bewertet. Das Modell mit dem besten Resultat wird anschliessend optimiert. Diese Optimierung besteht aus der Anpassung der Hyperparameter~\autocite{DesignML}.

% http://neuralnetworksanddeeplearning.com/chap1.html
Um eine Problemstellung mit einem neuronalen Netzwerk zu lösen, muss erst ein solches entworfen werden. Für das Design eines neuronalen Netzwerks gibt es keine klaren Regeln, vielmehr ist es eine Kunst. Der Input sowie der Output Layer sind oftmals durch die Problemstellung gegeben. Die Eigenschaften der zu analysierenden Problemstellung, sogenannte Features, definieren die Form des Input Layers. Bei gewissen Problemstellungen ist die Repräsentation dieser Eigenschaften klar. Zahlen werden auf eine einheitliche Skala skaliert und jede Zahl wird durch ein Neuron im Input Layer repräsentiert. Andere Arten von Eigenschaften, beispielsweise Wörter oder Sätze, können auf verschiedene Arten abgebildet werden. Im Fall von Wörtern und Sätzen gibt das gewählte Word embedding die Form des Input Layer vor. Der Output Layer ist durch die gesuchte Lösung gegeben. Im Fall eines Klassifizierungsproblemes wird meist eine One-Hot encoded Vektor als Output Layer verwendet. Dabei werden so viele Neuronen wie Anzahl möglicher Klassen angelegt. Das Neuron, welches die grösste Aktivierung vorweist, bestimmt die vorhergesagte Klasse~\autocite{NNDesign}.

Die Wahl der Anzahl, Art und Grösse der Hidden Layer ist die wahre Kunst beim Design eines neuronalen Netzwerks. Diese Entscheidungen ist meist eine Abwägung zwischen Trainingsaufwand und Genauigkeit des Modells. Für einfache Problemstellungen können viele versteckte Schichten schnell zum Overfitting führen. Bei komplexeren Problemstellungen sind dafür viele versteckte Schichten notwendig. Ein Modell mit nur einem einzigen Fully Connected Hidden Layer\footnote{Ein Fully Connected Layer beschreibt einen Layer, bei welchen jedes Neuron Eingaben von jedem Neuron aus der vorherigen Schicht erhält. Ein solcher Fully Connected Layer besteht somit aus mehreren Threshold Units, welche mit der vorherigen Schicht verbunden sind.} ist in der Lage eine handschriftliche Zahl zu erkennen. Für eine komplette OCR Lösung, welche Wörter, Sätze und ganze Paragraphen erkennt, ist ein tiefes Modell mit komplexen Schichten, wie LSTM Schichten, notwendig~\autocite{NNDesign}.

\subsection{End-to-end Entwicklung von künstlicher Intelligenz}
\label{chap:DAWN}

Dank des grossen Fortschritts im Bereich der künstlichen Intelligenz, können mit einfachen Mitteln bereits Modelle erstellt und trainiert werden. Trotz dieses grossen Fortschrittes ist die end-to-end Entwicklung und der Betrieb eines solchen Modells noch immer sehr aufwendig. Aus diesem Grund haben \textcite{DAWN} das fünf Jahre dauernde DAWN Forschungsprojekt an der Stanford Universität ins Leben gerufen. DAWN steht für Data Analytics for What's Next. Das Forschungsprojekt hat nicht zum Ziel, die Algorithmen im Bereich der künstlichen Intelligenz zu verbessern, sondern diese einfacher nutzbar zu machen. Damit in Zukunft keine grossen, kostenintensiven Teams von Statistikerinnen und Statistikern und Ingenieurinnen und Ingenieuren mehr benötigt werden, um erfolgreich eine künstliche Intelligenz zu entwickeln und betreiben, sind starke Verbesserungen im Bereich der Nutzbarkeit der Techniken rund um die künstliche Intelligenz notwendig~\autocite{DAWN}.

Der Versuch, kleine Teams von Fachspezialistinnen und Fachspezialisten zu befähigen, künstliche Intelligenz zu entwickeln und zu betreiben, vergleicht die Forschungsgruppe mit den Entwicklungen im Bereich der Suchmaschinen und Datenbanken. Während früher Suchmaschinen extrem komplex zu integrieren waren, kann eine solche heutzutage im Handumdrehen in eine Applikation integriert werden. Dabei liefert sie out-of-the-box bereits gute Ergebnisse. In den 1970er Jahren wurde durch die relationalen Datenbanken eine ähnliche Entwicklung angestossen. Vor den relationalen Datenbanken war der Betrieb und die Integration einer Datenbank komplex und aufwendig. Heute betreiben Unternehmen eine vielzahl von Applikationen, welche auf Datenbanken basieren~\autocite{DAWN}.

Das Forschungsprojekt hat zum Ziel, in den nächsten Jahren einen Stack zu entwickeln, welcher von der Hardware bis zu den Interfaces die end-to-end Entwicklung einer künstlichen Intelligenz vereinfacht. Dabei legt das Projekt besonders viel Wert auf die Aufbereitung von Daten, Selektion und Extraktion von Eigenschaften dieser Daten (sogenannte Features) sowie den Produktiven Betrieb der künstlichen Intelligenz~\autocite{DAWN}.
