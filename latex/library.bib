@misc{cs231NN,
author = {Karpathy, Andrej},
title = {{Neural Networks Part 1: Setting up the Architecture}},
url = {http://cs231n.github.io/neural-networks-1/},
urldate = {2019-04-28},
year = {2015}
}
@misc{CNN,
author = {Karpathy, Andrej},
title = {{Convolutional Neural Networks (CNNs / ConvNets)}},
url = {http://cs231n.github.io/convolutional-networks/},
urldate = {2019-04-25},
year = {2015}
}
@misc{NNDesign,
author = {Nielsen, Michael},
title = {{Using neural nets to recognize handwritten digits}},
url = {http://neuralnetworksanddeeplearning.com/chap1.html},
urldate = {2019-04-25},
year = {2018}
}
@article{tSNE,
abstract = {We present a new technique called “t-SNE” that visualizes high-dimensional data by giving each datapoint a location in a two or three-dimensional map. The technique is a variation of Stochastic Neighbor Embedding (Hinton and Roweis, 2002) that is much easier to optimize, and produces significantly better visualizations by reducing the tendency to crowd points together in the center of the map. t-SNE is better than existing techniques at creating a single map that reveals structure at many different scales. This is particularly important for high-dimensional data that lie on several different, but related, low-dimensional manifolds, such as images of objects from multiple classes seen from multiple viewpoints. For visualizing the structure of very large data sets, we show how t-SNE can use random walks on neighborhood graphs to allow the implicit structure of all of the data to influence theway in which a subset of the data is displayed. We illustrate the performance of t-SNE on a wide variety of data sets and compare it with many other non-parametric visualization techniques, including Sammon mapping, Isomap, and Locally Linear Embedding. The visualiza- tions produced by t-SNE are significantly better than those produced by the other techniques on almost all of the data sets.},
author = {van der Maaten, Laurens and Hinton, Geoffrey},
file = {:Users/sventschui/Downloads/vandermaaten08a.pdf:pdf},
issn = {02624079},
journal = {Journal of Machine Learning Research},
keywords = {dimensionality reduction,embedding algorithms,manifold learning,multidimensional scaling,visualization},
pages = {2579--2605},
pmid = {20652508},
title = {{Visualizing Data using t-SNE}},
volume = {9},
year = {2008}
}
@misc{SSD,
author = {Forson, Eddie},
title = {{Understanding SSD MultiBox — Real-Time Object Detection In Deep Learning}},
url = {https://towardsdatascience.com/understanding-ssd-multibox-real-time-object-detection-in-deep-learning-495ef744fab},
urldate = {2019-04-25},
year = {2017}
}
@misc{DAWN,
abstract = {http://arxiv.org/abs/1705.07538 Despite incredible recent advances in machine learning, building machine learning applications remains prohibitively time-consuming and expensive for all but the best-trained, best-funded engineering organizations. This expense comes not from a need for new and improved statistical models but instead from a lack of systems and tools for supporting end-to-end machine learning application development, from data preparation and labeling to productionization and monitoring. In this document, we outline opportunities for infrastructure supporting usable, end-to-end machine learning applications in the context of the nascent DAWN (Data Analytics for What's Next) project at Stanford.},
address = {Stanford, USA},
author = {Bailis, Peter and Olukotun, Kunle and R{\'{e}}, Christopher and Zaharia, Matei},
file = {:Users/sventschui/Downloads/1705.07538.pdf:pdf},
institution = {Stanford University},
title = {{Infrastructure for Usable Machine Learning: The Stanford DAWN Project}},
year = {2017}
}
@misc{RedditIE,
author = {O.V.},
title = {{Extracting a total cost from OCR paper receipt text - not sure on how to structure features with scikit}},
url = {https://www.reddit.com/r/MachineLearning/comments/53ovp9/extracting{\_}a{\_}total{\_}cost{\_}from{\_}ocr{\_}paper{\_}receipt/},
urldate = {2019-04-19},
year = {2016}
}
@article{OCRCorrection,
abstract = {Although OCR technology is now commonplace, character recognition errors are still a problem, in particular, in automated systems for information extraction from printed documents. This paper proposes a method for the automatic detection and correction of OCR errors in an information extraction system. Our algorithm uses domain-knowledge about possible misrecognition of characters to propose corrections; then it exploits knowledge about the type of the extracted information to perform syntactic and semantic checks in order to validate the proposed corrections. We assess our proposal on a real-world, highly challenging dataset composed of nearly 800 values extracted from approximately 100 commercial invoices and we obtained very good results. {\textcopyright} 2012 Infonomics Society.},
author = {Sorio, Enrico and Bartoli, Alberto and Davanzo, Giorgio and Medvet, Eric},
file = {:Users/sventschui/Downloads/06285067.pdf:pdf},
isbn = {9781908320056},
journal = {International Conference on Information Society (i-Society 2012) For},
pages = {151--155},
publisher = {IEEE},
title = {{A Domain Knowledge-based Approach for Automatic Correction of Printed Invoices}},
year = {2012}
}
@misc{DesignML,
author = {{Rom{\'{a}}n Aragay}, V{\'{i}}ctor},
title = {{How To Develop a Machine Learning Model From Scratch}},
url = {https://towardsdatascience.com/machine-learning-general-process-8f1b510bd8af},
urldate = {2019-04-19},
year = {2018}
}
@misc{DesignMLSecondaryCite,
author = {{Ari{\~{n}}o de la Rubia}, Eduardo},
title = {{Benchmarking Predictive Models}},
url = {https://blog.dominodatalab.com/benchmarking-predictive-models/},
urldate = {2019-04-19},
year = {2017}
}
@misc{CBR,
author = {Kolodner, Janet},
booktitle = {Encyclopedia of Education},
file = {:Users/sventschui/Downloads/instdesign.pdf:pdf},
isbn = {4048945041},
title = {{Instructional Design: Case-Based Reasoning}},
volume = {2},
year = {1999}
}
@misc{SSDFRCNN,
author = {Hui, Jonathan},
title = {{Object detection: speed and accuracy comparison (Faster R-CNN, R-FCN, SSD, FPN, RetinaNet and YOLOv3)}},
url = {https://medium.com/@jonathan{\_}hui/object-detection-speed-and-accuracy-comparison-faster-r-cnn-r-fcn-ssd-and-yolo-5425656ae359},
urldate = {2019-04-12},
year = {2018}
}
@misc{AP,
author = {Hui, Jonathan},
title = {{mAP (mean Average Precision) for Object Detection}},
url = {https://medium.com/@jonathan{\_}hui/map-mean-average-precision-for-object-detection-45c121a31173},
urldate = {2019-04-13},
year = {2018}
}
@misc{TesseractQuality,
author = {O.V.},
title = {{ImproveQuality}},
url = {https://github.com/tesseract-ocr/tesseract/wiki/ImproveQuality},
urldate = {2019-04-11},
year = {2019}
}
@misc{TDSLoss,
author = {Godoy, Daniel},
title = {{Understanding binary cross-entropy / log loss: a visual explanation}},
url = {https://towardsdatascience.com/understanding-binary-cross-entropy-log-loss-a-visual-explanation-a3ac6025181a},
urldate = {2019-04-10},
year = {2018}
}
@misc{IoU,
author = {Rosebrock, Adrian},
title = {{Intersection over Union (IoU) for object detection}},
url = {https://www.pyimagesearch.com/2016/11/07/intersection-over-union-iou-for-object-detection/},
urldate = {2019-04-13},
year = {2016}
}
@article{Howard2018,
abstract = {Inductive transfer learning has greatly impacted computer vision, but existing approaches in NLP still require task-specific modifications and training from scratch. We propose Universal Language Model Fine-tuning (ULMFiT), an effective transfer learning method that can be applied to any task in NLP, and introduce techniques that are key for fine-tuning a language model. Our method significantly outperforms the state-of-the-art on six text classification tasks, reducing the error by 18-24{\%} on the majority of datasets. Furthermore, with only 100 labeled examples, it matches the performance of training from scratch on 100x more data. We open-source our pretrained models and code.},
author = {Howard, Jeremy and Ruder, Sebastian},
file = {:Users/sventschui/Downloads/1801.06146.pdf:pdf},
title = {{Universal Language Model Fine-tuning for Text Classification}},
year = {2018}
}
@misc{BlueRiverTechnology,
author = {Marr, Bernard},
title = {{The Incredible Ways John Deere Is Using Artificial Intelligence To Transform Farming}},
url = {https://www.bernardmarr.com/default.asp?contentID=1387},
urldate = {2019-04-10}
}
@inproceedings{Hamza,
author = {Hamza, Hatem and Bela{\"{i}}d, Yolande and Bela{\"{i}}d, Abdel},
booktitle = {Ninth International Conference on Document Analysis and Recognition (ICDAR 2007)},
file = {:Users/sventschui/Downloads/version{\_}publiee{\_}IEEE.pdf:pdf},
isbn = {0769528228},
title = {{A case-based reasoning approach for invoice structure extraction}},
year = {2007}
}
@article{McAfee,
abstract = {https://thestarlab.com/wp-content/uploads/2017/09/The-Business-of-Artificial-Intelligence.pdf},
author = {Brynjolfsson, Erik and McAfee, Andrew},
file = {:Users/sventschui/Downloads/The-Business-of-Artificial-Intelligence.pdf:pdf},
journal = {Harvard Business Review},
number = {July 2017},
title = {{The Business of Artificial Intelligence}},
year = {2017}
}
@article{Mandal,
abstract = {The requirement of detection and identification of tables from document images is crucial to any document image analysis and digital library system. In this paper we report a very simple but extremely powerful approach to detect tables present in document pages. The algorithm relies on the observation that the tables have distinct columns which implies that gaps between the fields are substantially larger than the gaps between the words in text lines. This deceptively simple observation has led to the design of a simple but powerful table detection system with low computation cost. Moreover, mathematical foundation of the approach is also established including formation of a regular expression for ease of implementation.},
author = {Mandal, Sekhar and Chowdhury, Shyama P. and Das, Amit K. and Chanda, Bhabatosh},
file = {:Users/sventschui/Downloads/Mandal2006{\_}Article{\_}ASimpleAndEffectiveTableDetect.pdf:pdf},
issn = {14332833},
journal = {International Journal on Document Analysis and Recognition},
keywords = {Digital document library,Document image segmentation,Table detection},
number = {2-3},
pages = {172--182},
title = {{A simple and effective table detection system from document images}},
volume = {8},
year = {2006}
}
@misc{PingAnTechnology,
author = {{Ping An Technology}},
title = {{Ping An Technology}},
url = {https://tech.pingan.com/en/},
urldate = {2019-04-10}
}
@techreport{Ransbotham2017,
author = {Ransbotham, Sam and Kiron, David and Gerbert, Philipp and Reeves, Martin},
booktitle = {MIT Sloan Management Review},
file = {:Users/sventschui/Downloads/out.pdf:pdf},
title = {{Reshaping Business With Artificial Intelligence: Closing the Gap Between Ambition and Action}},
year = {2017}
}
@misc{Infervision,
author = {Marr, Bernard},
title = {{Infervision: Using AI And Deep Learning To Diagnose Cancer}},
url = {https://www.bernardmarr.com/default.asp?contentID=1269},
urldate = {2019-04-10}
}
@article{Campbell,
author = {Campbell, Murray and Hoane, A Joseph and Hsu, Feng-hsiung},
file = {:Users/sventschui/Downloads/1-s2.0-S0004370201001291-main.pdf:pdf},
journal = {Artificial Intelligence},
keywords = {computer chess,evaluation,game tree search,parallel search,search extensions,selective search},
pages = {57--83},
title = {{Deep Blue}},
volume = {134},
year = {2002}
}
@inproceedings{Vinge,
author = {Vinge, Vernor},
booktitle = {VISION-21 Symposium},
file = {:Users/sventschui/Downloads/19940022856.pdf:pdf},
title = {{The Coming Technological Singularity: How to Survive in a Post-Human Era}},
year = {1993}
}
@article{Weizenbaum,
author = {Weizenbaum, Joseph},
file = {:Users/sventschui/Downloads/ELIZA{\_}a{\_}computer{\_}program{\_}for{\_}the{\_}study{\_}o.pdf:pdf},
pages = {1--7},
title = {{ELIZA--A Computer Program For the Study of Natural Language Communication Between Man and Machine}},
year = {1966}
}
@misc{TDSAccuracy,
author = {Shung, Koo Ping},
booktitle = {Towards Data Science},
title = {{Accuracy, Precision, Recall or F1?}},
url = {https://towardsdatascience.com/accuracy-precision-recall-or-f1-331fb37c5cb9},
urldate = {2019-03-14},
year = {2018}
}
@misc{MLYearning,
author = {Ng, Andrew},
file = {:Users/sventschui/Downloads/Ng-MLY01-13.pdf:pdf},
title = {{Machine Learning Yearning}},
year = {2018}
}
@misc{StanfordGithubClassification,
author = {Karpathy, Andrej},
title = {{Image Classification}},
url = {http://cs231n.github.io/classification/},
urldate = {2019-03-14},
year = {2015}
}
@misc{Fungg2017ResNet,
author = {Fung, Vincent},
title = {{An Overview of ResNet and its Variants}},
url = {https://towardsdatascience.com/an-overview-of-resnet-and-its-variants-5281e2f56035},
urldate = {2019-03-09},
year = {2017}
}
@misc{SHTsuang2018Inception,
author = {Tsang, SH},
title = {{Review: Inception-v4 — Evolved From GoogLeNet, Merged with ResNet Idea (Image Classification)}},
url = {https://towardsdatascience.com/review-inception-v4-evolved-from-googlenet-merged-with-resnet-idea-image-classification-5e8c339d18bc},
urldate = {2019-03-09},
year = {2018}
}
@misc{GoogleTextClassification,
author = {O.V.},
title = {{Introduction | ML Universal Guides | Google Developers}},
url = {https://developers.google.com/machine-learning/guides/text-classification/},
urldate = {2019-03-09},
year = {2018}
}
@misc{TesseractTraining,
author = {O.V.},
title = {{TrainingTesseract 4.00}},
url = {https://github.com/tesseract-ocr/tesseract/wiki/TrainingTesseract-4.00},
urldate = {2019-03-09},
year = {2016}
}
@phdthesis{Buda2018,
abstract = {In this study, we systematically investigate the impact of class imbalance on classification performance of convolutional neural networks (CNNs) and compare frequently used methods to address the issue. Class imbalance is a common problem that has been comprehensively studied in classical machine learning, yet very limited systematic research is available in the context of deep learning. In our study, we use three benchmark datasets of increasing complexity, MNIST, CIFAR-10 and ImageNet, to investigate the effects of imbalance on classification and perform an extensive comparison of several methods to address the issue: oversampling, undersampling, two-phase training, and thresholding that compensates for prior class probabilities. Our main evaluation metric is area under the receiver operating characteristic curve (ROC AUC) adjusted to multi-class tasks since overall accuracy metric is associated with notable difficulties in the context of imbalanced data. Based on results from our experiments we conclude that (i) the effect of class imbalance on classification performance is detrimental; (ii) the method of addressing class imbalance that emerged as dominant in almost all analyzed scenarios was oversampling; (iii) oversampling should be applied to the level that completely eliminates the imbalance, whereas the optimal undersampling ratio depends on the extent of imbalance; (iv) as opposed to some classical machine learning models, oversampling does not cause overfitting of CNNs; (v) thresholding should be applied to compensate for prior class probabilities when overall number of properly classified cases is of interest.},
author = {Buda, Mateusz and Maki, Atsuto and Mazurowski, Maciej A.},
file = {:Users/sventschui/Downloads/1710.05381-2.pdf:pdf},
keywords = {Class imbalance,Convolutional neural networks,Deep learning,Image classification},
school = {Royal Institute of Technology (KTH)},
title = {{A systematic study of the class imbalance problem in convolutional neural networks}},
year = {2017}
}
@misc{TensorflowImageRetraining,
author = {O.V.},
title = {{How to Retrain an Image Classifier for New Categories}},
url = {https://www.tensorflow.org/hub/tutorials/image{\_}retraining},
urldate = {2019-03-09}
}
@article{Devlin2018,
abstract = {We introduce a new language representation model called BERT, which stands for Bidirectional Encoder Representations from Transformers. Unlike recent language representation models, BERT is designed to pre-train deep bidirectional representations by jointly conditioning on both left and right context in all layers. As a result, the pre-trained BERT representations can be fine-tuned with just one additional output layer to create state-of-the-art models for a wide range of tasks, such as question answering and language inference, without substantial task-specific architecture modifications. BERT is conceptually simple and empirically powerful. It obtains new state-of-the-art results on eleven natural language processing tasks, including pushing the GLUE benchmark to 80.4{\%} (7.6{\%} absolute improvement), MultiNLI accuracy to 86.7 (5.6{\%} absolute improvement) and the SQuAD v1.1 question answering Test F1 to 93.2 (1.5{\%} absolute improvement), outperforming human performance by 2.0{\%}.},
author = {Devlin, Jacob and Chang, Ming-Wei and Lee, Kenton and Toutanova, Kristina},
file = {:Users/sventschui/Downloads/1810.04805.pdf:pdf},
issn = {0140-525X},
pmid = {1000303116},
title = {{BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding}},
year = {2018}
}
@misc{GoogleAutoML,
author = {Le, Quoc and Zoph, Barret},
title = {{Using Machine Learning to Explore Neural Network Architecture}},
url = {https://ai.googleblog.com/2017/05/using-machine-learning-to-explore.html},
urldate = {2019-03-09},
year = {2017}
}
@misc{GoogleNasNet,
author = {Zoph, Barret and Vasudevan, Vijay and Shlens, Jonathon and Le, Quoc},
booktitle = {Google AI Blog},
title = {{AutoML for large scale image classification and object detection}},
url = {https://ai.googleblog.com/2017/11/automl-for-large-scale-image.html},
urldate = {2019-03-09},
year = {2017}
}
@misc{TDSTransferLearning,
author = {Marcelino, Pedro},
title = {{Transfer learning from pre-trained models}},
url = {https://towardsdatascience.com/transfer-learning-from-pre-trained-models-f2393f124751},
urldate = {2019-03-09},
year = {2018}
}
@article{He2015,
abstract = {Deeper neural networks are more difficult to train. We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously. We explicitly reformulate the layers as learning residual functions with reference to the layer inputs, instead of learning unreferenced functions. We provide comprehensive empirical evidence showing that these residual networks are easier to optimize, and can gain accuracy from considerably increased depth. On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers---8x deeper than VGG nets but still having lower complexity. An ensemble of these residual nets achieves 3.57{\%} error on the ImageNet test set. This result won the 1st place on the ILSVRC 2015 classification task. We also present analysis on CIFAR-10 with 100 and 1000 layers. The depth of representations is of central importance for many visual recognition tasks. Solely due to our extremely deep representations, we obtain a 28{\%} relative improvement on the COCO object detection dataset. Deep residual nets are foundations of our submissions to ILSVRC {\&} COCO 2015 competitions, where we also won the 1st places on the tasks of ImageNet detection, ImageNet localization, COCO detection, and COCO segmentation.},
author = {He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
file = {:Users/sventschui/Downloads/1512.03385.pdf:pdf},
isbn = {978-1-4673-8851-1},
issn = {1664-1078},
pmid = {23554596},
title = {{Deep Residual Learning for Image Recognition}},
year = {2015}
}
@misc{TheEconomist2010,
author = {{The Economist}},
title = {{Tech.View: Cars and software bugs}},
url = {https://www.economist.com/babbage/2010/05/16/techview-cars-and-software-bugs},
urldate = {2019-03-09},
year = {2010}
}
@article{Sarter1997,
author = {Sarter, Nadine B. and Woods, David D. and Billings, Charles E.},
file = {:Users/sventschui/Downloads/caebecd0f1b42d1eb8da1061e464fcccae11-2.pdf:pdf},
journal = {Handbook of Human Factors {\&} Ergonomics},
number = {2},
pages = {29--31},
title = {{Phase-change chalcogenide nonvolatile ram completely based on CMOS technology}},
year = {1997}
}
@article{Kregassner2012,
author = {Kerga{\ss}ner, Rudolf},
file = {:Users/sventschui/Downloads/Kerga{\~{A}}ner2012{\_}Article{\_}IT-AutomatisierungSchafftFreir.pdf:pdf},
journal = {Wirtschaftsinformatik {\&} Management},
pages = {20--23},
title = {{IT-Automatisierung schafft Freir{\"{a}}ume}},
volume = {6},
year = {2012}
}
@misc{VanRijsbergen1979,
address = {Glasgow, Schottland},
author = {van Rijsbergen, Cornelis Joost},
file = {:Users/sventschui/Downloads/Preface.pdf:pdf},
publisher = {University of Glasgow},
title = {{Information Retrieval}},
year = {1979}
}
@phdthesis{Kha2000,
abstract = {The Internet has becoming an increasingly important channel for both business-to-consumer and business-to-business e-commerce. It has changed the way many companies do business. Every day, more and more companies worldwide are being linked electronically. But the success rate in terms of profitability for these startups is low. This thesis focuses on business-to-consumer aspect of e-commerce. My research is to study the models from a set of online merchants and see how these companies translate their companies' e-business vision into reality. What are the critical factors these online merchants considered as they transform their companies into an e-commerce? This thesis identifies the key success factors of this technology strategy and model as well as helps understanding to what extent this success can be replicated in other markets and industries. Through detailed case studies on Amazon and Dell, we will analyze their strategies and identify the success factors that make them unique to thrive on this competitive landscape of the Digital Economy.},
author = {Kha, Le},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Kha - 2000 - Critical Success Factors for Business-to-Consumer E-business Lessons from Amazon and Dell Le Kha.pdf:pdf},
school = {Massachusetts Institute of Technology},
title = {{Critical Success Factors for Business-to-Consumer E-business: Lessons from Amazon and Dell Le Kha}},
year = {2000}
}
@article{Uettwiller-Geiger2005,
author = {Uettwiller-Geiger, D.L.},
file = {:Users/sventschui/Downloads/1205lab{\_}mgmt.pdf:pdf},
issn = {0580-7247},
journal = {Medical Laboratory Observer},
number = {12},
pages = {26},
title = {{A lab's strategy to reduce errors depends on automation}},
url = {http://www.mlo-online.com/articles/1205/1205lab{\_}mgmt.pdf},
volume = {37},
year = {2005}
}
@book{Lombriser2010,
address = {Z{\"{u}}rich, Schweiz},
author = {Lombriser, Roman and Abplanalp, Peter A},
edition = {6},
publisher = {Versus},
title = {{Strategisches Management}},
year = {2015}
}
@book{Capaul2010,
address = {Berlin, Deutschland},
author = {Capaul, Roman and Steingruber, Daniel},
edition = {2},
isbn = {978-3-06-028233-3},
publisher = {Cornelsen Schulverlage},
title = {{Betriebswirtschaft verstehen}},
year = {2010}
}
@article{Wright2018a,
abstract = {Recent advancements in robotics, artificial intelligence, machine learning, and sensors now enable machines to automate activities that once seemed safe from disruption—including tasks that rely on higher-level thinking, learning, tacit judgment, emotion sensing, and even disease detection. Despite these advancements, the ethical issues of business automation and artificial intelligence—and who will be affected and how—are less understood. In this article, we clarify and assess the cultural and ethical implications of business automation for stakeholders ranging from laborers to nations. We define business automation and introduce a novel framework that integrates stakeholder theory and social contracts theory. By integrating these theoretical models, our framework identifies the ethical implications of business automation, highlights best practices, offers recommendations, and uncovers areas for future research. Our discussion invites firms, policymakers, and researchers to consider the ethical implications of business automation and artificial intelligence when approaching these burgeoning and potentially disruptive business practices.},
author = {Wright, Scott A. and Schultz, Ainslie E.},
doi = {10.1016/j.bushor.2018.07.001},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Wright, Schultz - 2018 - The rising tide of artificial intelligence and business automation Developing an ethical framework.pdf:pdf},
issn = {00076813},
journal = {Business Horizons},
keywords = {Artificial intelligence,Automation,Business ethics,Social contracts theory,Stakeholder theory,Work displacement},
number = {6},
pages = {823--832},
publisher = {"Kelley School of Business, Indiana University"},
title = {{The rising tide of artificial intelligence and business automation: Developing an ethical framework}},
url = {https://doi.org/10.1016/j.bushor.2018.07.001},
volume = {61},
year = {2018}
}
@article{Ge2018,
abstract = {Neural sequence-to-sequence (seq2seq) approaches have proven to be successful in grammatical error correction (GEC). Based on the seq2seq framework, we propose a novel fluency boost learning and inference mechanism. Fluency boosting learning generates diverse error-corrected sentence pairs during training, enabling the error correction model to learn how to improve a sentence's fluency from more instances, while fluency boosting inference allows the model to correct a sentence incrementally with multiple inference steps. Combining fluency boost learning and inference with convolutional seq2seq models, our approach achieves the state-of-the-art performance: 75.72 (F{\_}{\{}0.5{\}}) on CoNLL-2014 10 annotation dataset and 62.42 (GLEU) on JFLEG test set respectively, becoming the first GEC system that reaches human-level performance (72.58 for CoNLL and 62.37 for JFLEG) on both of the benchmarks.},
author = {Ge, Tao and Wei, Furu and Zhou, Ming},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Ge, Wei, Zhou - 2018 - Reaching Human-level Performance in Automatic Grammatical Error Correction An Empirical Study.pdf:pdf},
number = {3},
pages = {1--15},
title = {{Reaching Human-level Performance in Automatic Grammatical Error Correction: An Empirical Study}},
url = {http://arxiv.org/abs/1807.01270},
year = {2018}
}
@article{Chowdhury2003,
author = {Chowdhury, Gobinda G.},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Chowdhury - 2003 - Natural language processing.pdf:pdf},
journal = {Annual review of information science and technology},
number = {1},
pages = {51--89},
title = {{Natural language processing}},
volume = {37},
year = {2003}
}
@misc{Olah2015,
author = {Olah, Christopher},
title = {{Understanding LSTM Networks}},
url = {http://colah.github.io/posts/2015-08-Understanding-LSTMs/},
urldate = {2018-11-28},
year = {2015}
}
@misc{Mugan2018,
author = {Mugan, Jonathan},
title = {{Pers{\"{o}}nliche Kommunikation per E-Mail}},
year = {2018}
}
@misc{Scheidl2018,
author = {Scheidl, Harald},
title = {{An Intuitive Explanation of Connectionist Temporal Classification}},
url = {https://towardsdatascience.com/intuitively-understanding-connectionist-temporal-classification-3797e43a86c},
urldate = {2018-11-28},
year = {2018}
}
@misc{Olah2014,
author = {Olah, Christopher},
title = {{Conv Nets: A Modular Perspective}},
url = {http://colah.github.io/posts/2014-07-Conv-Nets-Modular/},
urldate = {2018-11-28},
year = {2014}
}
@article{Collobert2011,
abstract = {We propose a unified neural network architecture and learning algorithm that can be applied to various natural language processing tasks including: part-of-speech tagging, chunking, named entity recognition, and semantic role labeling. This versatility is achieved by trying to avoid task-specific engineering and therefore disregarding a lot of prior knowledge. Instead of exploiting man-made input features carefully optimized for each task, our system learns internal representations on the basis of vast amounts of mostly unlabeled training data. This work is then used as a basis for building a freely available tagging system with good performance and minimal computational requirements.},
author = {Collobert, Ronan and Weston, Jason and Bottou, Leon and Karlen, Michael and Kavukcuoglu, Koray and Kuksa, Pavel},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Collobert et al. - 2011 - Natural Language Processing (almost) from Scratch.0398v1:0398v1},
journal = {The Journal of Machine Learning Research},
pages = {2493--2537},
title = {{Natural Language Processing (almost) from Scratch}},
volume = {12},
year = {2011}
}
@techreport{Turian2010,
abstract = {If we take an existing supervised NLP system , a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih {\&} Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize. com/projects/wordreprs/},
author = {Turian, Joseph and Ratinov, Lev and Bengio, Yoshua},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Turian, Ratinov, Bengio - 2010 - Word representations A simple and general method for semi-supervised learning.pdf:pdf},
title = {{Word representations: A simple and general method for semi-supervised learning}},
url = {http://metaoptimize.},
year = {2010}
}
@inproceedings{Bengio2001,
abstract = {http://books.google.com/books?id=Mgs2FwtgNxwC},
address = {Cambridge, USA},
author = {Bengio, Yoshua and Ducharme, R{\'{e}}jean and Vincent, Pascal},
isbn = {978-0-262-12241-2},
publisher = {MIT Press},
title = {{A Neural Probabilistic Language Model}},
year = {2001}
}
@misc{Olah2014a,
author = {Olah, Christopher},
title = {{Neural Networks, Manifolds, and Topology}},
url = {http://colah.github.io/posts/2014-03-NN-Manifolds-Topology/{\#}fn1},
urldate = {2018-11-28},
year = {2014}
}
@misc{Olah2014b,
author = {Olah, Christopher},
title = {{Deep Learning, NLP, and Representations}},
url = {http://colah.github.io/posts/2014-07-NLP-RNNs-Representations/},
urldate = {2018-11-28},
year = {2014}
}
@article{Krogh2008,
abstract = {Artificial neural networks have been applied to problems ranging from$\backslash$nspeech recognition to prediction of protein secondary structure,$\backslash$nclassification of cancers and gene prediction. How do they work and$\backslash$nwhat might they be good for?},
author = {Krogh, Anders},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Krogh - 2008 - What are artificial neural networks.pdf:pdf},
journal = {Nature Biotechnology},
number = {2},
pages = {195},
title = {{What are artificial neural networks?}},
volume = {26},
year = {2008}
}
@misc{Volk,
author = {Volk, Martin},
title = {{Formale Grammatiken und Syntaxanalyse: Strukturelle Mehrdeutigkeiten}},
url = {https://files.ifi.uzh.ch/cl/volk/SyntaxVorl/Vorl{\_}10.Ambig.html{\#}Bsp72},
urldate = {2018-11-28}
}
@phdthesis{Xiao2004,
author = {Xiao, Luo},
school = {Friedrich-Alexander-Universit{\"{a}}t Erlangen-N{\"{u}}rnberg (FAU)},
title = {{Information extraction in the practical applications}},
year = {2004}
}
@misc{GrammarlyInc.2018,
author = {{Grammarly Inc.}},
title = {{Grammarly: Official Site | Free Grammar Checker}},
url = {https://www.grammarly.com},
urldate = {2018-11-28},
year = {2018}
}
@misc{GoogleLLC2018,
author = {{Google LLC}},
title = {{Google Docs: Kostenlos Dokumente online erstellen und bearbeiten}},
url = {https://www.google.com/intl/de{\_}ch/docs/about/},
urldate = {2018-11-28},
year = {2018}
}
@misc{MicrosoftCorporation2018,
author = {{Microsoft Corporation}},
title = {{Microsoft Word – Textverarbeitungssoftware | Office}},
url = {https://products.office.com/de-ch/word},
urldate = {2018-11-28},
year = {2018}
}
@misc{LanguageTool2018,
author = {LanguageTool},
title = {{LanguageTool - Pr{\"{u}}fung f{\"{u}}r Rechtschreibung und Grammatik}},
url = {https://languagetool.org/de/},
urldate = {2018-11-28},
year = {2018}
}
@misc{Piskorski2012,
author = {Piskorski, Jakub and Yangarber, Roman},
booktitle = {Multi-source, Multilingual Information Extraction and Summarization. Theory and Applications of Natural Language Processing},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Piskorski, Yangarber - 2012 - Information Extraction Past, Present and Future.pdf:pdf},
publisher = {Springer, Berlin, Heidelberg},
title = {{Information Extraction: Past, Present and Future}},
url = {www.springer.com/librarians/e-content/mycopy},
year = {2012}
}
@article{Xue2014,
author = {Xue, Yafang},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Carter - 2004 - Patents versus settling for the soft option.pdf:pdf},
journal = {Department of Biomedical Engineering, University of Michigan},
title = {{Optical Character Recognition}},
year = {2014}
}
@techreport{BAG2016,
address = {Bern, Schweiz},
author = {BAG},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/BAG - 2016 - Antworten auf h{\"{a}}ufig gestellte Fragen (FAQ) zur Versichertenkarte.pdf:pdf},
title = {{Antworten auf h{\"{a}}ufig gestellte Fragen (FAQ) zur Versichertenkarte}},
url = {https://www.bag.admin.ch/dam/bag/de/dokumente/kuv-leistungen/Versichertenkarte/faq-versichertenkarte.pdf.download.pdf},
year = {2016}
}
@article{Kirchgassner2009,
author = {Kirchg{\"{a}}ssner, G},
journal = {Die Volkswirtschaft. Das Magazin f{\"{u}}r Wirtschaftspolitik},
number = {11/2019},
pages = {4--8},
title = {{Das schweizerische Gesundheitswesen: Kostenentwicklung}},
year = {2009}
}
@book{Madorin2014,
author = {Mad{\"{o}}rin, Mascha},
isbn = {978-3-9524121-2-1},
publisher = {ZHAW Departement Gesundheit, Institut f{\"{u}}r Pflege},
title = {{{\"{O}}konomisierung des Gesundheitswesens − Erkundungen aus der Sicht der Pflege}},
year = {2014}
}
@misc{TheEconomist2018,
abstract = {AI will mainly be good for business, but mind the pitfalls},
author = {{The Economist}},
booktitle = {The Economist},
title = {{The sunny and the dark side of AI}},
url = {https://www.economist.com/special-report/2018/03/28/the-sunny-and-the-dark-side-of-ai},
urldate = {2018-11-25},
year = {2018}
}
@article{Lu2018,
abstract = {Artificial intelligence (AI) is an important technology that supports daily social life and economic activities. It contributes greatly to the sustainable growth of Japan's economy and solves various social problems. In recent years, AI has attracted attention as a key for growth in developed countries such as Europe and the United States and developing countries such as China and India. The attention has been focused mainly on developing new artificial intelligence information communication technology (ICT) and robot technology (RT). Although recently developed AI technology certainly excels in extracting certain patterns, there are many limitations. Most ICT models are overly dependent on big data, lack a self-idea function, and are complicated. In this paper, rather than merely developing next-generation artificial intelligence technology, we aim to develop a new concept of general-purpose intelligence cognition technology called “Beyond AI”. Specifically, we plan to develop an intelligent learning model called “Brain Intelligence (BI)” that generates new ideas about events without having experienced them by using artificial life with an imagine function. We will also conduct demonstrations of the developed BI intelligence learning model on automatic driving, precision medical care, and industrial robots.},
author = {Lu, Huimin and Li, Yujie and Chen, Min and Kim, Hyoungseop and Serikawa, Seiichi},
isbn = {1103601709},
journal = {Mobile Networks and Applications},
keywords = {Artificial intelligence,Artificial life,Brain intelligence},
title = {{Brain Intelligence: Go beyond Artificial Intelligence}},
year = {2018}
}
@misc{ExplosionAI,
author = {{Explosion AI}},
title = {{Industrial-Strength Natural Language Processing}},
url = {https://spacy.io},
urldate = {2018-11-18}
}
@misc{StanfordNLPGroup,
author = {{Stanford NLP Group}},
title = {{Stanford Named Entity Recognizer (NER)}},
url = {https://nlp.stanford.edu/software/CRF-NER.shtml},
urldate = {2018-11-18}
}
@inproceedings{Borthwick1998,
abstract = {INTRODUCTION: This paper describes a new system called Maximum Entropy Named Entity" or MENE" ?pronounced meanie"? which was NYU's entrant in the MUC-7 named entity evaluation. By working within the frame- work of maximum entropy theory and utilizing a exible object-based architecture, the system is able to make use of an extraordinarily diverse range of knowledge sources in making its tagging decisions. These knowledge sources include capitalization features, lexical features and features indicating the current type of text ?i.e. headline or main body?. It makes use of a broad array of dictionaries of useful single or multi-word terms such as rst names, company names, and corporate su xes. These dictionaries required no manual editing and were either downloaded from the web or were simply obvious" lists entered by hand.},
address = {New York, New York},
author = {Borthwick, Andrew and Sterling, John and Agichtein, Eugene and Grishman, Ralph},
booktitle = {Seventh Message Understanding Conference},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Borthwick et al. - Unknown - NYU Description of the MENE Named Entity System as Used in MUC-7.pdf:pdf},
publisher = {New York University},
title = {{NYU: Description of the MENE Named Entity System as used in MUC-7}},
year = {1998}
}
@misc{Mugan,
author = {Mugan, Jonathan},
title = {{Evaluation and Comparison}},
url = {http://www.deepgrammar.com/evaluation},
urldate = {2018-11-18}
}
@misc{Weiss2016,
author = {Weiss, Tal},
title = {{Deep Spelling}},
url = {https://machinelearnings.co/deep-spelling-9ffef96a24f6},
urldate = {2018-11-18},
year = {2016}
}
@misc{O.V.2018,
author = {O.V.},
title = {{4.0 Accuracy and Performance}},
url = {https://github.com/tesseract-ocr/tesseract/wiki/4.0-Accuracy-and-Performance},
urldate = {2018-11-17},
year = {2018}
}
@misc{O.V.2018a,
author = {O.V.},
title = {{4.0 with LSTM}},
url = {https://github.com/tesseract-ocr/tesseract/wiki/4.0-with-LSTM},
urldate = {2018-11-17},
year = {2018}
}
@inproceedings{Smith2007,
abstract = {The Tesseract OCR engine, as was the HP Research Prototype in the UNLV Fourth Annual Test of OCR Accuracy, is described in a comprehensive overview. Emphasis is placed on aspects that are novel or at least unusual in an OCR engine, including in particular the line finding, features/classification methods, and the adaptive classifier.},
author = {Smith, Ray},
booktitle = {Proceedings of the International Conference on Document Analysis and Recognition, ICDAR},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Smith - 2007 - An overview of the tesseract OCR engine.pdf:pdf},
isbn = {0769528228},
keywords = {OCR},
mendeley-tags = {OCR},
title = {{An overview of the tesseract OCR engine}},
year = {2007}
}
@misc{Neuberg2017,
author = {Neuberg, Brad},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Neuberg - 2017 - Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning.webarchive:webarchive},
title = {{Creating a Modern OCR Pipeline Using Computer Vision and Deep Learning}},
url = {https://blogs.dropbox.com/tech/2017/04/creating-a-modern-ocr-pipeline-using-computer-vision-and-deep-learning/},
urldate = {2018-11-17},
year = {2017}
}
@article{Gottfredson1997,
abstract = {Mainstream science on intelligence : an editorial with 52 signatories , history , and bibliography . Linda Gottfredson. Intelligence , Jan-Feb 1997 v24 n1 p13(11). Abstract: Highly regarded scholars from various social science disciplines have voiced their support for a collective. ... $\backslash$n},
author = {Gottfredson, Linda S.},
isbn = {0160-2896},
journal = {Intelligence},
title = {{Mainstream science on intelligence: An editorial with 52 signatories, history, and bibliography}},
year = {1997}
}
@book{Sternberg1977,
abstract = {DNA polymerases are enzymes that copy the genetic material within a cell using a strand of an existing double helix as a template to guide the synthesis of a new DNA strand. Since DNA is continuously exposed to damaging agents, and damaged DNA can derail the DNA replication machinery; a cell must either repair or bypass (via a process called translesion synthesis) this damage to copy its genome.$\backslash$n$\backslash$nMost living things, from bacteria to humans, have specific DNA polymerases for translesion synthesis that can copy past damaged DNA, such as DNA Polymerase V in the bacterium E. coli . However, DNA polymerase V will also often introduce mistakes when it copies DNA that is not damaged—and cells will subsequently switch to use a different polymerase to accurately copy undamaged DNA.$\backslash$n$\backslash$nDNA polymerase V is activated by binding to a protein called RecA and a molecule of adenosine triphosphate (ATP for short). ATP stores energy, which cells release by breaking down the molecule into simpler chemicals: but how do ATP and RecA work together to activate this polymerase?$\backslash$n$\backslash$nNow, Erdem, Jaszczur et al. have addressed this question using biochemical techniques on purified polymerases, proteins and DNA fragments in a test tube. These experiments reveal that DNA polymerase V must bind to an ATP molecule before it can attach to the DNA template, and must remain bound to ATP while synthesizing the new DNA strand. After the activated polymerase has attached to the DNA, it will break down the molecule of ATP to free itself from the DNA. Furthermore, although the RecA protein can also break down ATP, Erdem, Jaszczur et al. found that a mutant RecA without this ability could still activate DNA polymerase V to break down this molecule itself.$\backslash$n$\backslash$nBinding to and breaking down a molecule of ATP by a DNA polymerase has not been observed before as a method of directly regulating these enzymes' activity. Erdem, Jaszcuzur et al. suggest that, in living cells, this extra level of control would limit how long the DNA polymerase V spends attached to the DNA. As such, this polymerase would only be used to copy stretches of damaged DNA, but would not continue on to copy neighboring stretches of undamaged DNA where it would likely introduce new errors.$\backslash$n$\backslash$nDOI: [http://dx.doi.org/10.7554/eLife.02384.002][1]$\backslash$n$\backslash$n [1]: /lookup/doi/10.7554/eLife.02384.002},
author = {Sternberg, Robert J},
booktitle = {Intelligence, information processing, and analogical reasoning: The componential analysis of human abilities.},
isbn = {0470991372},
keywords = {*Cognitive Processes,*Intelligence,Theories},
title = {{Intelligence, information processing, and analogical reasoning: The componential analysis of human abilities.}},
year = {1977}
}
@article{Minaya-Collado1998,
abstract = {After a brief discussion about the counter-intuitive results of a first approach like "intelligence as the ability of universal compression" we present a formal definition of exception-free description. Then we introduce a variant E of algorithmic complexity that we name intensional complexity with the only additional property that it allows no 'exceptions', making formal this deep notion in the very theory. Once defined this variant and a time-weighted version Et that we name explanatory complexity we retake the analogy and formulate the idea that "intelligence is the ability of comprehension" understanding this last term in a formal way: explanatory compression. Finally, we devise a test based on k-incomprehensible strings and we present an effective algorithm for generating them. To dissipate its ethereal appearance, we devote most of the paper to present some computational, philosophical, psychological, psychometric and other experimental facts that support such a definition. We 'unfold' the definition to fill the gap between the formalities and the classical IQ tests. This relation to psychometrics leads us immediately to propose a framework to evaluate artificial-or not-intelligent systems. In the end we take a step forward from the evaluation into the understanding and design of intelligent systems. 0 Apologies First, we must apologise for the title because it 'forces' to pay more attention than we are deserving. Secondly, we apologise for some unorthodox treatment, oversimplifications and partial views of the related areas we discuss. And last, we apologise for the haste we are taking for presenting it without the observation of some specialists of the different fields this article deals about. Right or wrong, we think there is no reason to keep back the current state of our theory for quick reproof or further improvement. In the end, we think we have an intriguing view of 'intension' and what follows is, for the moment, the most we have been able to do from its interpretation.},
author = {Minaya-Collado, Neus and Hernandez-Orallo, Jose},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Minaya-Collado, Hernandez-Orallo - 1998 - A Formal Definition of Intelligence Based on an Intensional Variant of Algorithmic Complexity.pdf:pdf},
journal = {Proceedings of International Symposium of Engineering of Intelligent Systems},
pages = {146----163},
title = {{A Formal Definition of Intelligence Based on an Intensional Variant of Algorithmic Complexity}},
year = {1998}
}
@article{Legg2007,
abstract = {Although the definition and measurement of intelligence is clearly of fundamental importance to the field of artificial intelligence, no general survey of definitions and tests of machine intelligence exists. Indeed few researchers are even aware of alternatives to the Turing test and its many derivatives. In this paper we fill this gap by providing a short survey of the many tests of machine intelligence that have been proposed.},
author = {Legg, Shane and Hutter, Marcus},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Legg, Hutter - 2007 - Universal intelligence A definition of machine intelligence.pdf:pdf},
isbn = {0924-6495},
journal = {Minds and Machines},
keywords = {AIXI,Complexity theory,Definitions,Intelligence,Intelligence tests,Measures,Theoretical foundations,Turing test},
title = {{Universal intelligence: A definition of machine intelligence}},
year = {2007}
}
@techreport{Santosh,
author = {Santosh, K C},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Santosh - Unknown - Document Image Analysis Current Trends and Challenges in Graphics Recognition.pdf:pdf},
title = {{Document Image Analysis Current Trends and Challenges in Graphics Recognition}}
}
@techreport{Bughin,
abstract = {Bughin, Jacques Hazan, Eric Ramaswamy, Sree Chui, Michael Allas, Tera www.mckinsey.com/mgi.},
author = {{McKinsey Global Institute}},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Bughin et al. - Unknown - ARTIFICIAL INTELLIGENCE THE NEXT DIGITAL FRONTIER.pdf:pdf},
keywords = {Investing in an Age of Technology Disruption Backg},
title = {{Artificial Intelligence the next digital frontier?}},
year = {2017}
}
@unpublished{Scherer2015,
abstract = {Artificial intelligence technology (or AI) has developed rapidly during the past decade, and the effects of the AI revolution are already being keenly felt in many sectors of the economy. A growing chorus of commentators, scientists, and entrepreneurs has expressed alarm regarding the increasing role that autonomous machines are playing in society, with some suggesting that government regulation may be necessary to reduce the public risks that AI will pose. Unfortunately, the unique features of AI and the manner in which AI can be developed present both practical and conceptual challenges for the legal system. These challenges must be confronted if the legal system is to positively impact the development of AI and ensure that aggrieved parties receive compensation when AI systems cause harm. This article will explore the public risks associated with AI and the competencies of government institutions in managing those risks. It concludes with a proposal for an indirect form of AI regulation based on differential tort liability.},
annote = {The struggle of AI},
author = {Scherer, Matthew U.},
booktitle = {SSRN},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Scherer - 2015 - Regulating Artificial Intelligence Systems Risks, Challenges, Competencies, and Strategies.pdf:pdf},
isbn = {9781498734837},
keywords = {Artificial Intelligence,Emerging Technologies,K29,K49,Law,O32,O38,Regulation},
title = {{Regulating Artificial Intelligence Systems: Risks, Challenges, Competencies, and Strategies}},
year = {2015}
}
@techreport{Kolbjornsrud2016,
annote = {Practice 1: Leave Administration to AI},
author = {Kolbj{\o}rnsrud, Vegard and Amico, Richard and Thomas, Robert J},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Kolbj{\o}rnsrud, Amico, Thomas - 2016 - How Artificial Intelligence Will Redefine Management.pdf:pdf},
title = {{How Artificial Intelligence Will Redefine Management}},
year = {2016}
}
@article{Brynjolfsson,
abstract = {Profound change is coming, but roles for humans remain},
author = {Brynjolfsson, Erik and tom Mitchell},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Brynjolfsson, Mitchell - Unknown - What can machine learning do Workforce implications.pdf:pdf},
title = {{What can machine learning do? Workforce implications}}
}
@article{Tredinnick2017,
abstract = {2017 promises to be the year when artificial intelligence (AI) moves out of film and fiction and into the workplace. While automation has become commonplace in retail and services, from the ubiquitous uptake of automatic tills to the growing influence intelligent service agents, anxiety about the impact of AI on professional roles has been gra-dually increasing in popular discourse. Writing in the Guardian in December 2016, theoretical physicist Stephen Hawking warned that 'the rise of artificial intelligence is likely to extend this job destruction deep into the middle classes, with only the most caring, creative or supervisory roles remaining' (Hawking, 2016). A report in the Tele-graph has warned that 'many middle-class professionals will be outsourced to machines within the next few decades' (Knapton, 2016). Automation – once the preserve of manufacturing – is threating to overtake the professional and managerial classes. Anxieties about the impact of AI on professional jobs are not new. Half a century ago, the father of modern com-puting Alan Turing predicted 'great opposition from the intellectuals who were afraid of being put out of a job' and added that 'once the machine thinking method had started, it would not take long to outstrip our feeble powers' (1951: 475). At some stage, Turing argued, 'we should have expect the machines to take control' (1951: 475). Although we are not yet at that stage, it seems inevitable that AI will have a significant impact on professional jobs over the next few decades and may even perhaps threaten the very exis-tence of numerous professional fields. This coming social and economic transformation has become known as the fourth industrial revolution; following on from the ages of steam, electricity and information technology, the age of automation, machine learning and AI is almost upon us. But what is AI, in what kinds of areas is it currently being exploited and what is coming in the near future? This special edition of Out-of-the-Box explores the emerging area of AI, automation and machine learning in business and professional contexts. It will review the current state of play of intelligent systems, and how they are making their way into commercial contexts.},
annote = {sehr cool. 2017 das jahr der AI},
author = {Tredinnick, Luke},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Tredinnick - 2017 - Artificial intelligence and professional roles.pdf:pdf},
issn = {17416450},
journal = {Business Information Review},
pages = {37--41},
title = {{Artificial intelligence and professional roles}},
volume = {34},
year = {2017}
}
@techreport{Brynjolfsson2017,
abstract = {We live in an age of paradox. Systems using artificial intelligence match or surpass human-level performance in more and more domains, leveraging rapid advances in other technologies and driving soaring stock prices. Yet measured productivity growth has declined by half over the past decade, and real income has stagnated since the late 1990s for a majority of Americans. We describe four potential explanations for this clash of expectations and statistics: false hopes, mismeasurement, redistribution and implementation lags. While a case can be made for each explanation, we argue that lags have likely been the biggest contributor to the paradox. The most impressive capabilities of AI, particularly those based on machine learning, have not yet diffused widely. More importantly, like other general purpose technologies, their full effects won't be realized until waves of complementary innovations are developed and implemented. The adjustment costs, organizational changes, and new skills needed for successful AI can be modeled as a kind of intangible capital. A portion of the value of this intangible capital is already reflected in the market value of firms. However, going forward, national statistics could fail to measure the full benefits of the new technologies and some may even have the wrong sign. Acknowledgements: We thank},
annote = {Kritik an AI, es ben{\"{o}}tigt noch Komplement{\"{a}}r-Erfindungen, damit Potential genutzt werden kann},
author = {Brynjolfsson, Erik and School, Sloan and Rock, Daniel and Abrams, Eliot and Agrawal, Ajay and Autor, David and Benzell, Seth and Gans, Joshua and Goldfarb, Avi and Goolsbee, Austan and Saint-Jacques, Guillaume and Meyer, Andrea and Tratjenberg, Manuel},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Brynjolfsson et al. - 2017 - Artificial Intelligence and the Modern Productivity Paradox A Clash of Expectations and Statistics.pdf:pdf},
title = {{Artificial Intelligence and the Modern Productivity Paradox: A Clash of Expectations and Statistics *}},
url = {http://www.khoslaventures.com/fireside-chat-with-google-co-founders-larry-page-and-sergey-brin},
year = {2017}
}
@article{Patricio2018,
abstract = {Grain production plays an important role in the global economy. In this sense, the demand for efficient and safe methods of food production is increasing. Information Technology is one of the tools to that end. Among the available tools, we highlight computer vision solutions combined with artificial intelligence algorithms that achieved important results in the detection of patterns in images. In this context, this work presents a systematic review that aims to identify the applicability of computer vision in precision agriculture for the production of the five most produced grains in the world: maize, rice, wheat, soybean, and barley. In this sense, we present 25 papers selected in the last five years with different approaches to treat aspects related to disease detection, grain quality, and phenotyping. From the results of the systematic review, it is possible to identify great opportunities, such as the exploitation of GPU (Graphics Processing Unit) and advanced artificial intelligence techniques, such as DBN (Deep Belief Networks) in the construction of robust methods of computer vision applied to precision agriculture.},
annote = {Anwendung KI in Landwirtschaft f{\"{u}}r die Automatisierung},
author = {Patr{\'{i}}cio, Diego In{\'{a}}cio and Rieder, Rafael},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Patr{\'{i}}cioa, Riederb - Unknown - Computer vision and artificial intelligence in precision agriculture for grain T crops A systematic revi.pdf:pdf},
journal = {Computers and Electronics in Agriculture},
keywords = {Artificial intelligence,Computer vision,Precision agriculture,Systematic review},
pages = {69--81},
title = {{Computer vision and artificial intelligence in precision agriculture for grain crops: A systematic review}},
volume = {153},
year = {2018}
}
@techreport{CSSGruppe2018,
address = {Luzern, Schweiz},
annote = {Gesch{\"{a}}ftsbericht CSS Gruppe

Kennzahlen

Betriebsaufwand f{\"{u}}r eigene Rechnung},
author = {{CSS Gruppe}},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/CSS Gruppe - 2018 - Gesch{\"{a}}ftsbericht 2017.pdf:pdf},
title = {{Gesch{\"{a}}ftsbericht 2017}},
year = {2018}
}
@book{Goodfellow2016,
address = {Cambridge, USA},
author = {Goodfellow, Ian and Bengio, Yoshua and Courville, Aaron},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Goodfellow, Bengio, Courville - 2016 - Deep learning.pdf:pdf},
publisher = {MIT Press},
title = {{Deep learning}},
year = {2016}
}
@book{Russell2009,
abstract = {The long-anticipated revision of this {\#}1 selling book offers the most comprehensive, state of the art introduction to the theory and practice of artificial intelligence for modern applications.Intelligent Agents. Solving Problems by Searching. Informed Search Methods. Game Playing. Agents that Reason Logically. First-order Logic. Building a Knowledge Base. Inference in First-Order Logic. Logical Reasoning Systems. Practical Planning. Planning and Acting. Uncertainty. Probabilistic Reasoning Systems. Making Simple Decisions. Making Complex Decisions. Learning from Observations. Learning with Neural Networks. Reinforcement Learning. Knowledge in Learning. Agents that Communicate. Practical Communication in English. Perception. Robotics.For computer professionals, linguists, and cognitive scientists interested in artificial intelligence.},
address = {New Jersey, USA},
author = {Russell, Stuart J. and Norvig, Peter},
booktitle = {Pearson},
edition = {3},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Russell, Norvig - 2009 - Artificial Intelligence A Modern Approach, 3rd edition.pdf:pdf},
isbn = {9780136042594},
publisher = {Prentice Hall},
title = {{Artificial Intelligence: A Modern Approach}},
year = {2009}
}
@article{Nadeau2007,
abstract = {This survey covers fifteen years of research in the Named Entity Recognition and Classification (NERC) field, from 1991 to 2006. We report observations about languages, named entity types, domains and textual genres studied in the literature. From the start, NERC systems have been developed using hand-made rules, but now machine learning techniques are widely used. These techniques are surveyed along with other critical aspects of NERC such as features and evaluation methods. Features are word-level, dictionary-level and corpus-level representations of words in a document. Evaluation techniques, ranging from intuitive exact match to very complex matching techniques with adjustable cost of errors, are an indisputable key to progress.},
author = {Nadeau, David and Sekine, Satoshi},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/Nadeau, Sekine - 2007 - A survey of named entity recognition and classification.pdf:pdf},
journal = {Lingvisticae Investigationes},
number = {1},
pages = {3--26},
publisher = {John Benjamins},
title = {{A survey of named entity recognition and classification}},
volume = {30},
year = {2007}
}
@misc{Finanzen.ch2017,
author = {Finanzen.ch},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/finanzen.ch - 2017 - Axa Winterthur will bis 2020 100'000 Kunden in der Zusatzversicherung gewinnen.webarchive:webarchive},
title = {{Axa Winterthur will bis 2020 100'000 Kunden in der Zusatzversicherung gewinnen}},
url = {https://www.finanzen.ch/nachrichten/finanzplanung/axa-winterthur-will-bis-2020-100000-kunden-in-der-zusatzversicherung-gewinnen-1002138512},
urldate = {2018-10-30},
year = {2017}
}
@misc{EDI2017,
author = {EDI},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/EDI - 2017 - Faktenblatt Verg{\"{u}}tungssysteme.pdf:pdf},
title = {{Faktenblatt Verg{\"{u}}tungssysteme}},
url = {https://www.priminfo.admin.ch/downloads/fragen-und-antworten/Fiche d informationtiers payant-tiers garant{\_}DE{\_}2018.pdf},
urldate = {2018-10-30},
year = {2017}
}
@misc{BfS2017,
author = {BfS},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/BfS - 2017 - Kosten und Finanzierung des Gesundheitswesens 2015 Provisorische Daten.pdf:pdf},
title = {{Kosten und Finanzierung des Gesundheitswesens 2015: Provisorische Daten}},
url = {https://www.bfs.admin.ch/bfs/de/home/statistiken/kataloge-datenbanken/medienmitteilungen.assetdetail.2360359.html},
urldate = {2018-10-30},
year = {2017}
}
@misc{BfS2018,
author = {BfS},
file = {:Users/sventschui/Library/Application Support/Mendeley Desktop/Downloaded/BfS - 2018 - Finanzierung.webarchive:webarchive},
title = {{Finanzierung}},
url = {https://www.bfs.admin.ch/bfs/de/home/statistiken/gesundheit/kosten-finanzierung/finanzierung.html},
urldate = {2018-10-30},
year = {2018}
}
